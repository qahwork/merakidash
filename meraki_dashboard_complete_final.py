# Meraki Network Analytics Dashboard - Complete Fixed Version
# Fixed metrics calculation and enhanced traffic analysis display
import streamlit as st
import meraki
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import warnings
import os
import sys
import time

# Parallel processing imports
import concurrent.futures
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
from functools import partial
import logging
import queue
import time

# Performance optimization: Enable parallel API calls for maximum speed
# This implementation uses ThreadPoolExecutor to run multiple API calls simultaneously
# Expected performance improvement: 3-5x faster data loading compared to sequential calls

# Suppress Streamlit ScriptRunContext warnings in parallel threads
logging.getLogger("streamlit.runtime.scriptrunner.script_runner").setLevel(logging.ERROR)

# Set environment variable to suppress Streamlit warnings
import os
os.environ["STREAMLIT_LOGGER_LEVEL"] = "ERROR"

# Additional warning suppression for parallel processing
import warnings
warnings.filterwarnings("ignore", message=".*missing ScriptRunContext.*")
warnings.filterwarnings("ignore", category=UserWarning, module="streamlit")

# Set up thread-local warning suppression
import threading
_thread_local = threading.local()

def setup_thread_warnings():
    """Setup warning suppression for each thread"""
    if not hasattr(_thread_local, 'warnings_setup'):
        import warnings
        import os
        # Set environment variable for this thread
        os.environ["STREAMLIT_LOGGER_LEVEL"] = "ERROR"
        warnings.filterwarnings("ignore", message=".*missing ScriptRunContext.*")
        warnings.filterwarnings("ignore", category=UserWarning, module="streamlit")
        warnings.filterwarnings("ignore", category=RuntimeWarning, module="streamlit")
        _thread_local.warnings_setup = True

warnings.filterwarnings('ignore')

# Session persistence
import json
import hashlib
from pathlib import Path

# Configuration
try:
    # Try to import from current directory first
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    from config import MERAKI_API_KEY, DEFAULT_ORGANIZATION, DEFAULT_NETWORKS, DEFAULT_TIMESPAN, DEFAULT_RESOLUTION, DEFAULT_BANDWIDTH_ANALYSIS, SHOW_DEBUG_INFO
except ImportError:
    try:
        # Try to import from Documents/merakitest
        sys.path.insert(0, os.path.expanduser("~/Documents/merakitest"))
        from config import MERAKI_API_KEY, DEFAULT_ORGANIZATION, DEFAULT_NETWORKS, DEFAULT_TIMESPAN, DEFAULT_RESOLUTION, DEFAULT_BANDWIDTH_ANALYSIS, SHOW_DEBUG_INFO
    except ImportError:
        # Fallback to safe default values - NO HARDCODED API KEYS
        MERAKI_API_KEY = None  # Must be set via config.py or environment variable
        DEFAULT_ORGANIZATION = None  # Must be set via config.py
        DEFAULT_NETWORKS = []
        DEFAULT_TIMESPAN = "Last 24 hours"
        DEFAULT_RESOLUTION = "5 minutes"
        DEFAULT_BANDWIDTH_ANALYSIS = ["WAN Uplinks (Primary/Secondary)", "Peak vs Average Analysis"]
        SHOW_DEBUG_INFO = False

# Page config
st.set_page_config(
    page_title="Meraki Network Analytics Dashboard",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better text visibility and layout optimization
st.markdown("""
<style>
    /* ========== TOP PADDING REMOVAL - ENHANCED VERSION ========== */
    /* Based on suggested approach but with broader compatibility */
    
    /* Main content area - multiple selectors for version compatibility */
    .css-18e3th9, .main .block-container, .block-container {
        padding-top: 0rem !important;
        padding-bottom: 0rem !important;
        margin-top: 0rem !important;
        max-width: 100% !important;
        font-size: 0.9rem;
        line-height: 1.4;
    }
    
    /* Header removal - comprehensive approach */
    .stApp > header, header, .css-1v0mbdj {
        background-color: transparent !important;
        height: 0rem !important;
        padding-top: 0rem !important;
        margin-top: 0rem !important;
        visibility: hidden;
    }
    
    /* Main container - multiple selectors */
    .main, .css-k1ih3n {
        padding-top: 0rem !important;
        margin-top: 0rem !important;
    }
    
    /* Sidebar content - enhanced with suggested classes */
    .css-1lcbmhc, .css-1d391kg, section[data-testid="stSidebar"] {
        padding-top: 0rem !important;
        margin-top: 0rem !important;
        font-size: 0.85rem;
        line-height: 1.3;
    }
    
    /* Sidebar inner elements */
    section[data-testid="stSidebar"] > div, 
    .sidebar .sidebar-content,
    .css-1lcbmhc > div:first-child {
        padding-top: 0rem !important;
        margin-top: 0rem !important;
    }
    
    /* App container - comprehensive removal */
    .stApp, .css-1y4p8pa {
        margin-top: 0px !important;
        padding-top: 0px !important;
    }
    
    /* Hide Streamlit branding completely */
    #MainMenu, footer, .css-14xtw13 {visibility: hidden;}
    
    /* ========== SIDEBAR FONT SIZE INCREASE ========== */
    /* Increase font size for organization and network selection */
    
    /* Organization selection label - more specific selectors */
    .stSidebar .stSelectbox label,
    .stSidebar .stSelectbox > label,
    .stSidebar .stSelectbox label[data-testid="stSelectboxLabel"],
    .stSidebar .stSelectbox .stMarkdown {
        font-size: 1.2rem !important;
        font-weight: 700 !important;
        color: #262730 !important;
    }
    
    /* Network selection label - more specific selectors */
    .stSidebar .stMultiSelect label,
    .stSidebar .stMultiSelect > label,
    .stSidebar .stMultiSelect label[data-testid="stMultiSelectLabel"],
    .stSidebar .stMultiSelect .stMarkdown {
        font-size: 1.2rem !important;
        font-weight: 700 !important;
        color: #262730 !important;
    }
    
    /* Selectbox and multiselect input text */
    .stSidebar .stSelectbox > div > div > div,
    .stSidebar .stMultiSelect > div > div > div {
        font-size: 1rem !important;
    }
    
    /* Sidebar headers */
    .stSidebar .stMarkdown h1,
    .stSidebar .stMarkdown h2,
    .stSidebar .stMarkdown h3 {
        font-size: 1.3rem !important;
        font-weight: 700 !important;
    }
    
    /* Sidebar text content */
    .stSidebar .stMarkdown {
        font-size: 1.1rem !important;
    }
    
    /* Sidebar buttons */
    .stSidebar .stButton > button {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
    }
    
    /* Force all sidebar text to be larger */
    .stSidebar * {
        font-size: 1.1rem !important;
    }
    
    /* Specific targeting for selectbox and multiselect labels */
    .stSidebar div[data-testid="stSelectbox"] label,
    .stSidebar div[data-testid="stMultiSelect"] label {
        font-size: 1.2rem !important;
        font-weight: 700 !important;
        color: #262730 !important;
    }
    
    /* ========== FORCE SIDEBAR VISIBILITY ========== */
    /* Force sidebar to always be visible even when closed */
    
    /* Force sidebar to always show */
    section[data-testid="stSidebar"] {
        display: block !important;
        visibility: visible !important;
        width: 300px !important;
        min-width: 300px !important;
    }
    
    /* Force sidebar content to be visible */
    .stSidebar .stMarkdown,
    .stSidebar .stSelectbox,
    .stSidebar .stMultiSelect,
    .stSidebar .stButton {
        display: block !important;
        visibility: visible !important;
    }
    
    /* Ensure sidebar doesn't get hidden */
    .stSidebar {
        display: block !important;
        visibility: visible !important;
    }
    
    /* Force sidebar to stay open */
    .css-1d391kg {
        display: block !important;
        visibility: visible !important;
    }
    
    /* First element in any container */
    .element-container:first-child, 
    .css-1wrcr25:first-child {
        margin-top: 0rem !important;
        padding-top: 0rem !important;
    }
    
    /* Force all top-level elements to start from top */
    .css-1wrcr25, .element-container {
        margin-top: 0rem !important;
    }
    
    /* Prevent text truncation in tables and dataframes */
    .dataframe {
        font-size: 0.8rem;
        white-space: nowrap;
        overflow: visible;
    }
    
    /* Ensure long text in cells is not truncated */
    .dataframe td {
        white-space: nowrap;
        overflow: visible;
        text-overflow: unset;
        max-width: none;
    }
    
    /* Optimize metric containers */
    .metric-container {
        font-size: 0.8rem;
    }
    
    /* Optimize chart titles */
    .plotly .gtitle {
        font-size: 1rem !important;
    }
    
    /* Optimize button sizes */
    .stButton > button {
        font-size: 0.85rem;
        padding: 0.5rem 1rem;
    }
    
    /* Optimize selectbox and input sizes */
    .stSelectbox > div > div,
    .stTextInput > div > div > input {
        font-size: 0.85rem;
    }
    
    /* Optimize expander headers */
    .streamlit-expanderHeader {
        font-size: 0.9rem;
    }
    
    /* Optimize alert containers */
    .alert-container {
        font-size: 0.8rem;
    }
    
    /* Prevent text truncation in client names and MAC addresses */
    .client-name, .mac-address {
        white-space: nowrap;
        overflow: visible;
        text-overflow: unset;
        max-width: none;
        font-size: 0.85rem;
    }
    
    /* Optimize sidebar spacing */
    .sidebar .sidebar-content {
        padding: 1rem 0.5rem;
    }
    
    /* Optimize sidebar header spacing */
    .sidebar .sidebar-content .element-container {
        margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# Login system with persistent session
SESSION_FILE = Path.home() / ".meraki_dashboard_session.json"

def save_login_session(username):
    """Save login session to file"""
    try:
        session_data = {
            'username': username,
            'logged_in': True,
            'timestamp': datetime.now().isoformat(),
            'token': hashlib.sha256(f"{username}{datetime.now().date()}".encode()).hexdigest()
        }
        with open(SESSION_FILE, 'w') as f:
            json.dump(session_data, f)
        print(f"âœ… ì„¸ì…˜ ì €ì¥ë¨: {SESSION_FILE}")
    except Exception as e:
        print(f"âš ï¸ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_login_session():
    """Load login session from file"""
    try:
        if SESSION_FILE.exists():
            with open(SESSION_FILE, 'r') as f:
                session_data = json.load(f)
            
            # Check if session is still valid (created today)
            session_date = datetime.fromisoformat(session_data['timestamp']).date()
            if session_date == datetime.now().date():
                print(f"âœ… ì €ì¥ëœ ì„¸ì…˜ ë³µì›: {session_data['username']}")
                return session_data
            else:
                print(f"âš ï¸ ì„¸ì…˜ ë§Œë£Œë¨ (ë‚ ì§œ: {session_date})")
                SESSION_FILE.unlink()  # Delete expired session
        return None
    except Exception as e:
        print(f"âš ï¸ ì„¸ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def clear_login_session():
    """Clear login session file"""
    try:
        if SESSION_FILE.exists():
            SESSION_FILE.unlink()
            print(f"âœ… ì„¸ì…˜ ì‚­ì œë¨")
    except Exception as e:
        print(f"âš ï¸ ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}")

def check_login():
    """Check if user is logged in"""
    # First check session state
    if st.session_state.get('logged_in', False):
        return True
    
    # If not in session state, try to load from file
    saved_session = load_login_session()
    if saved_session and saved_session.get('logged_in'):
        # Restore session to session state
        st.session_state.logged_in = True
        st.session_state.username = saved_session.get('username')
        print(f"âœ… ìë™ ë¡œê·¸ì¸: {saved_session.get('username')}")
        return True
    
    return False

def login_page():
    """Display login page"""
    # Create centered container using columns
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        # Application branding
        st.markdown("""
            <div style="text-align: center; padding: 1rem 0; margin-bottom: 1.5rem;">
                <div style="margin-bottom: 0.5rem;">
                    <span style="color: #1f2937; font-size: 2.5rem; font-weight: bold; font-family: Arial, sans-serif;">
                        ğŸŒ Meraki Dashboard
                    </span>
                </div>
                    <p style="color: #666; font-size: 0.9rem; margin: 0; font-family: Arial, sans-serif;">
                    Network Analytics & Management Platform
                </p>
            </div>
            """, unsafe_allow_html=True)
            
        # Login form title and description
        st.markdown(
            '<h2 style="display:inline-block; font-weight:bold;">ğŸŒ  Meraki Network Analytics Dashboard</h2>',
            unsafe_allow_html=True
        )
        st.markdown("**ë¡œê·¸ì¸í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œì— ì ‘ì†í•˜ì„¸ìš”**")
        st.markdown("")
        
        with st.form("login_form"):
            st.markdown("#### ğŸ” ë¡œê·¸ì¸")
            username = st.text_input("ì‚¬ìš©ìëª…", placeholder="ì‚¬ìš©ìëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            
            st.markdown("")
            submitted = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True, type="primary")
        
        if submitted:
            # Load credentials from config
            try:
                from config import LOGIN_USERNAME, LOGIN_PASSWORD
                if username == LOGIN_USERNAME and password == LOGIN_PASSWORD:
                    st.session_state.logged_in = True
                    st.session_state.username = username
                    # Save login session to file for persistence
                    save_login_session(username)
                    st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ! ì„¸ì…˜ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    time.sleep(0.5)  # Brief pause to show success message
                    st.rerun()
                else:
                    st.error("ì˜ëª»ëœ ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤.")
            except ImportError:
                st.error("ë¡œê·¸ì¸ ì„¤ì •ì´ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. config.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    # Add some bottom spacing
    st.markdown("<br><br>", unsafe_allow_html=True)

def logout():
    """Logout user"""
    st.session_state.logged_in = False
    st.session_state.username = None
    # Clear saved session file
    clear_login_session()
    st.rerun()

# Check login first
if not check_login():
    login_page()
    st.stop()

# Sidebar: Application Logo
st.sidebar.markdown("""
<div style="text-align: center; margin-bottom: 1rem;">
    <span style="color: #1f2937; font-size: 1.8rem; font-weight: bold; font-family: Arial, sans-serif;">
        ğŸŒ Meraki Dashboard
    </span>
    <p style="color: #666; margin: 0; font-size: 0.8rem; font-family: Arial, sans-serif;">
        Network Analytics Platform
    </p>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("</div>", unsafe_allow_html=True)

# Sidebar: User info with clickable logout hyperlink
username = st.session_state.get('username', 'User')

# Create clickable logout using form submission
with st.sidebar:
    # Create a form that submits when the link is clicked
    with st.form(key="logout_form", clear_on_submit=True):
        st.markdown(f"""
        <div style="margin-bottom: 0;">
            <span style="color: #374151; font-weight: 500;">ì‚¬ìš©ì: </span>
            <span style="color: #1f2937; font-weight: 600;">{username}</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Hidden submit button that gets triggered by JavaScript
        logout_submitted = st.form_submit_button("ğŸ”“ë¡œê·¸ì•„ì›ƒ")
        
        if logout_submitted:
            logout()

# Hide the submit button with CSS and add JavaScript functionality
st.sidebar.markdown("""
<style>
/* Hide the logout form submit button */
form[data-testid="form"] button[kind="formSubmit"] {
    display: none !important;
    visibility: hidden !important;
    height: 0 !important;
    width: 0 !important;
    margin: 0 !important;
    padding: 0 !important;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    function setupLogoutClick() {
        // Find the logout text and make it clickable
        const logoutLink = document.getElementById('logout-link');
        if (logoutLink) {
            logoutLink.addEventListener('click', function() {
                // Find and click the hidden submit button
                const form = logoutLink.closest('form');
                if (form) {
                    const submitBtn = form.querySelector('button[type="submit"]');
                    if (submitBtn) {
                        submitBtn.click();
                    }
                }
            });
        }
    }
    
    // Setup immediately and also after a short delay for dynamic content
    setupLogoutClick();
    setTimeout(setupLogoutClick, 100);
    setTimeout(setupLogoutClick, 500);
});
</script>
""", unsafe_allow_html=True)

# Sidebar: API configuration - Hidden for cleaner UI
# st.sidebar.header("ğŸ”‘ Meraki API ì„¤ì •")
# api_key = st.sidebar.text_input("API í‚¤", value=MERAKI_API_KEY, type="password", disabled=True, help="API í‚¤ëŠ” config.pyì—ì„œ ë¡œë“œë©ë‹ˆë‹¤")
# st.sidebar.info(f"ğŸ”‘ API í‚¤ ë¡œë“œë¨: {MERAKI_API_KEY[:10]}...{MERAKI_API_KEY[-4:]}")

# Set api_key for internal use (hidden from UI)
api_key = MERAKI_API_KEY

# API Version and Status - Hidden for cleaner UI
# st.sidebar.markdown("### ğŸ“¡ API Status")
# st.sidebar.success("âœ… API v1.62.0 Connected")
# st.sidebar.markdown("**Base URL:** api.meraki.com/api/v1")
# st.sidebar.markdown("**Last Updated:** Sep 3, 2025")
# st.sidebar.markdown("**Authentication:** X-Cisco-Meraki-API-Key")

# API Capabilities - Hidden for cleaner UI
# st.sidebar.markdown("### ğŸš€ API Capabilities")
# capabilities = [
#     "ğŸŒ Network Management",
#     "ğŸ“± Device Configuration", 
#     "ğŸ”’ Security Monitoring",
#     "ğŸ“Š Analytics & Insights",
#     "ğŸ“¶ Wireless Management",
#     "âš¡ Automation Tools",
#     "ğŸ”§ Bulk Operations",
#     "ğŸ“ˆ Performance Monitoring"
# ]
# for cap in capabilities:
#     st.sidebar.markdown(f"â€¢ {cap}")
# Sidebar: Navigation
#st.sidebar.header("ğŸ“Š ë©”ë‰´")

# Initialize current_page in session state if not exists
if 'current_page' not in st.session_state:
    st.session_state.current_page = "ë©”ì¸í™”ë©´"

# Navigation options
nav_options = [
    ("ğŸ“Š ë©”ì¸í™”ë©´", "ë©”ì¸í™”ë©´"),
    ("ğŸŒ íŠ¸ë˜í”½ ë¶„ì„", "íŠ¸ë˜í”½ ë¶„ì„"),
    ("ğŸ‘¥ í´ë¼ì´ì–¸íŠ¸ ë¶„ì„", "í´ë¼ì´ì–¸íŠ¸ ë¶„ì„"),
    ("ğŸ”Œ ìŠ¤ìœ„ì¹˜ í¬íŠ¸", "ìŠ¤ìœ„ì¹˜ í¬íŠ¸"),
    ("ğŸš¨ ë””ë°”ì´ìŠ¤ ìƒíƒœ ì•Œë¦¼", "ë””ë°”ì´ìŠ¤ ìƒíƒœ ì•Œë¦¼"),
    ("ğŸ“„ ë¼ì´ì„¼ìŠ¤ ì •ë³´", "ë¼ì´ì„¼ìŠ¤ ì •ë³´")
]

# Create navigation buttons
for icon_name, page_key in nav_options:
    if st.sidebar.button(
        icon_name,
        key=f"nav_{page_key}",
        use_container_width=True,
        type="primary" if st.session_state.current_page == page_key else "secondary"
    ):
        st.session_state.current_page = page_key
        st.rerun()



st.sidebar.markdown("---")

# Sidebar: Analysis settings
st.sidebar.header("ğŸ“Š ë¶„ì„ ì„¤ì •")
time_ranges = {
    "ì§€ë‚œ 1ì‹œê°„": 3600,
    "ì§€ë‚œ 2ì‹œê°„": 7200,
    "ì§€ë‚œ 24ì‹œê°„": 86400,
    "ì§€ë‚œ 3ì¼": 259200,
    "ì§€ë‚œ 1ì£¼": 604800,
    "ì§€ë‚œ 1ê°œì›”": 2592000
}

# Initialize timespan in session state if not exists
if 'selected_timespan' not in st.session_state:
    st.session_state.selected_timespan = DEFAULT_TIMESPAN if DEFAULT_TIMESPAN in time_ranges else "ì§€ë‚œ 24ì‹œê°„"

selected_timespan = st.sidebar.selectbox(
    "ì‹œê°„ ë²”ìœ„", 
    list(time_ranges.keys()), 
    index=list(time_ranges.keys()).index(st.session_state.selected_timespan),
    key="timespan_selectbox"
)
timespan = time_ranges[selected_timespan]

# Update session state when timespan changes
if selected_timespan != st.session_state.selected_timespan:
    st.session_state.selected_timespan = selected_timespan

resolution_options = {
    "1ë¶„ ê°„ê²©": 60,
    "5ë¶„ ê°„ê²©": 300,
    "15ë¶„ ê°„ê²©": 900,
    "1ì‹œê°„ ê°„ê²©": 3600,
    "1ì¼ ê°„ê²©": 86400
}

# Initialize resolution in session state if not exists
if 'selected_resolution' not in st.session_state:
    st.session_state.selected_resolution = DEFAULT_RESOLUTION if DEFAULT_RESOLUTION in resolution_options else "5ë¶„ ê°„ê²©"

selected_resolution = st.sidebar.selectbox(
    "ë°ì´í„° ìˆ˜ì§‘ ê°„ê²©", 
    list(resolution_options.keys()), 
    index=list(resolution_options.keys()).index(st.session_state.selected_resolution),
    key="resolution_selectbox"
)
resolution = resolution_options[selected_resolution]

# Update session state when resolution changes
if selected_resolution != st.session_state.selected_resolution:
    st.session_state.selected_resolution = selected_resolution

st.sidebar.markdown("---")

# Real-time data load time tracking in sidebar
from datetime import datetime

# Initialize data load time in session state if not exists
if 'data_load_time' not in st.session_state:
    st.session_state.data_load_time = datetime.now()

# Calculate elapsed time since data was loaded
current_time = datetime.now()
elapsed_time = current_time - st.session_state.data_load_time

# Format elapsed time - always HH:MM:SS format
total_seconds = int(elapsed_time.total_seconds())
hours = total_seconds // 3600
minutes = (total_seconds % 3600) // 60
seconds = total_seconds % 60

# Always display in HH:MM:SS format
elapsed_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"

# Color coding based on elapsed time
if total_seconds > 300:  # 5 minutes
    delta_color = "inverse"
    status_text = "ìƒˆë¡œê³ ì¹¨ ê¶Œì¥"
elif total_seconds > 180:  # 3 minutes
    delta_color = "normal"
    status_text = "ì •ìƒ"
else:
    delta_color = "normal"
    status_text = "ìµœì‹ "

# Get the initial elapsed time for JavaScript
initial_elapsed = (datetime.now() - st.session_state.data_load_time).total_seconds()

# Display elapsed time in sidebar with real-time update
st.sidebar.markdown("### â±ï¸ ë°ì´í„° ê²½ê³¼ì‹œê°„")

# JavaScript-based real-time counter for sidebar
st.sidebar.markdown(f"""
<script>
// Store the initial elapsed time when page loads
let initialElapsed = {initial_elapsed};
let startTime = new Date().getTime() / 1000;

function updateSidebarTimer() {{
    // Calculate current elapsed time
    let currentTime = new Date().getTime() / 1000;
    let totalElapsed = initialElapsed + (currentTime - startTime);
    
    // Format as HH:MM:SS
    let hours = Math.floor(totalElapsed / 3600);
    let minutes = Math.floor((totalElapsed % 3600) / 60);
    let seconds = Math.floor(totalElapsed % 60);
    
    let timeStr = String(hours).padStart(2, '0') + ':' + 
                 String(minutes).padStart(2, '0') + ':' + 
                 String(seconds).padStart(2, '0');
    
    // Update the sidebar timer display
    let sidebarTimerElement = document.getElementById('sidebar-elapsed-timer');
    if (sidebarTimerElement) {{
        sidebarTimerElement.textContent = timeStr;
    }}
    
    // Update status based on elapsed time
    let statusElement = document.getElementById('sidebar-timer-status');
    if (statusElement) {{
        if (totalElapsed > 300) {{
            statusElement.textContent = 'ìƒˆë¡œê³ ì¹¨ ê¶Œì¥';
            statusElement.style.color = '#dc2626';
        }} else if (totalElapsed > 180) {{
            statusElement.textContent = 'ì •ìƒ';
            statusElement.style.color = '#059669';
        }} else {{
            statusElement.textContent = 'ìµœì‹ ';
            statusElement.style.color = '#059669';
        }}
    }}
}}

// Update timer every second
setInterval(updateSidebarTimer, 1000);

// Update immediately
updateSidebarTimer();
</script>

<div style="text-align: center; padding: 10px; background: #f8fafc; border-radius: 8px; border: 1px solid #e5e7eb;">
    <div id="sidebar-elapsed-timer" style="font-size: 1.5rem; font-weight: 700; color: #1f2937; margin-bottom: 5px;">{elapsed_str}</div>
    <div id="sidebar-timer-status" style="font-size: 0.8rem; font-weight: 500;">{status_text}</div>
</div>
""", unsafe_allow_html=True)
# Sidebar: Feature toggles (hidden)
enable_traffic = True
enable_clients = True
enable_switch_ports = True
enable_bandwidth = True
enable_alerts = True

# Initialize API
@st.cache_resource
def init_api(key):
    if not key:
        return None
    try:
        return meraki.DashboardAPI(key, suppress_logging=True)
    except Exception as e:
        st.error(f"Failed to initialize Meraki API: {e}")
        return None

# Parallel processing helper functions
def suppress_streamlit_warnings():
    """Suppress Streamlit warnings in parallel threads"""
    import warnings
    import logging
    
    # Suppress specific warnings
    warnings.filterwarnings("ignore", message=".*missing ScriptRunContext.*")
    warnings.filterwarnings("ignore", category=UserWarning, module="streamlit")
    warnings.filterwarnings("ignore", category=RuntimeWarning, module="streamlit")
    
    # Suppress logging warnings
    logging.getLogger("streamlit.runtime.scriptrunner.script_runner").setLevel(logging.ERROR)
    logging.getLogger("streamlit.runtime.scriptrunner").setLevel(logging.ERROR)

def safe_api_call(func, *args, **kwargs):
    """Safely execute API call with error handling"""
    try:
        # Setup thread-specific warning suppression
        setup_thread_warnings()
        suppress_streamlit_warnings()
        return func(*args, **kwargs)
    except Exception as e:
        if SHOW_DEBUG_INFO:
            print(f"API call failed: {func.__name__} - {e}")
        return None

def parallel_api_calls(api_calls, max_workers=100):  # EXTREME workers for 10-second target
    """Execute multiple API calls in parallel with EXTREME worker count for 10-second target"""
    results = {}
    
    # Suppress warnings at the start of parallel execution
    suppress_streamlit_warnings()
    
    # EXTREME optimize worker count for 10-second target
    if len(api_calls) < max_workers:
        max_workers = len(api_calls)
    
    # EXTREME max workers for fastest processing
    max_workers = min(max_workers, 200)  # Increased to 200 for maximum speed
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_key = {
            executor.submit(safe_api_call, call['func'], *call.get('args', []), **call.get('kwargs', {})): call['key']
            for call in api_calls
        }
        
        # Collect results as they complete
        for future in as_completed(future_to_key):
            key = future_to_key[future]
            try:
                result = future.result()
                results[key] = result
            except Exception as e:
                if SHOW_DEBUG_INFO:
                    print(f"Failed to get result for {key}: {e}")
                results[key] = None
    
    return results

def parallel_data_loading(load_functions, api_key, **common_params):
    """Load multiple data types in parallel"""
    api_calls = []
    
    for func_name, func in load_functions.items():
        # Prepare function arguments
        args = [api_key]
        if 'org_id' in common_params:
            args.append(common_params['org_id'])
        if 'network_id' in common_params:
            args.append(common_params['network_id'])
        if 'timespan' in common_params:
            args.append(common_params['timespan'])
        if 'resolution' in common_params:
            args.append(common_params['resolution'])
        
        api_calls.append({
            'key': func_name,
            'func': func,
            'args': args
        })
    
    return parallel_api_calls(api_calls)


# Get all organizations without filtering (filtering will be done at network level)
@st.cache_data(ttl=300, show_spinner="ì¡°ì§ ì •ë³´ ë¡œë”© ì¤‘...")  # Cache for 5 minutes
def get_all_organizations(key):
    """Get list of all organizations without filtering"""
    try:
        from datetime import datetime
        
        print("=" * 60)
        print("LOADING ALL ORGANIZATIONS (NO FILTERING)")
        print("=" * 60)
        
        start_time = datetime.now()
        
        api = init_api(key)
        if not api:
            print("âŒ Failed to initialize API")
            print("=" * 60)
            # Don't cache failed results
            raise Exception("Failed to initialize Meraki API")
        
        # Get all organizations
        print("ğŸ“‹ Getting all organizations...")
        print(f"ğŸ”‘ API Key: {key[:10]}...{key[-4:]}")
        
        try:
            organizations = api.organizations.getOrganizations()
            print(f"ğŸ“Š Found {len(organizations)} total organizations")
            
            if not organizations or len(organizations) == 0:
                print("âŒ No organizations returned from API")
                print("=" * 60)
                # Don't cache empty results
                raise Exception("No organizations found - API returned empty list")
                
        except Exception as api_error:
            print(f"âŒ API Call Failed: {str(api_error)}")
            print(f"âŒ Error Type: {type(api_error).__name__}")
            import traceback
            print(f"âŒ Traceback: {traceback.format_exc()}")
            print("=" * 60)
            # Re-raise to prevent caching
            raise
        
        # Convert to simple list format
        org_list = []
        for org in organizations:
            org_list.append({
                'id': org.get('id'),
                'name': org.get('name', 'Unknown')
            })
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 60)
        print("ORGANIZATION LOADING SUMMARY")
        print("=" * 60)
        print(f"Total organizations: {len(org_list)}")
        print(f"â±ï¸  Total time: {duration:.2f} seconds")
        print("=" * 60)
        
        return org_list
        
    except Exception as e:
        print(f"ğŸ’¥ Error in get_all_organizations: {e}")
        print(f"ğŸ’¥ Error Type: {type(e).__name__}")
        import traceback
        print(f"ğŸ’¥ Full Traceback:")
        print(traceback.format_exc())
        print("=" * 60)
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to get organizations: {e}")
        # Re-raise to prevent caching failed results
        raise


# Load all organizations (no filtering at organization level) - Optimized for speed
@st.cache_data(ttl=300, show_spinner="ì¡°ì§ ëª©ë¡ ë¡œë”© ì¤‘...")  # Reduced TTL
def load_orgs(key):
    """Load all organizations - filtering will be done at network level"""
    try:
        print("=" * 60)
        print("LOADING ORGANIZATIONS (NO FILTERING)")
        print("=" * 60)
        
        # Get all organizations
        all_orgs = get_all_organizations(key)
        
        print(f"ğŸ“‹ Final organization list: {len(all_orgs)} organizations")
        for i, org in enumerate(all_orgs, 1):
            print(f"  {i}. {org['name']} ({org['id']})")
        
        print("=" * 60)
        return all_orgs
    except Exception as e:
        print(f"ğŸ’¥ Error in load_orgs: {e}")
        print("=" * 60)
        st.error(f"Failed to load organizations: {e}")
        # Re-raise to prevent caching
        raise

# Ultra-fast critical data loading for immediate display
@st.cache_data(ttl=15, show_spinner="ì¤‘ìš” ë°ì´í„° ë¡œë”© ì¤‘...")  # Ultra-short TTL
def load_critical_data_fast(key, org_id):
    """Load only critical data for immediate display"""
    try:
        print("ğŸš€ Loading critical data for immediate display...")
        start_time = datetime.now()
        
        # Load only the most essential data
        devices = load_devices(key, org_id)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âš¡ Critical data loaded in {duration:.2f} seconds")
        return devices
        
    except Exception as e:
        print(f"ğŸ’¥ Error loading critical data: {e}")
        return []

# EXTREME SPEED: Minimal data loading for 10-second target
@st.cache_data(ttl=5, show_spinner="ì´ˆê³ ì† ë¡œë”© ì¤‘...")  # Ultra-minimal TTL
def load_dashboard_data_parallel(key, org_id, network_ids, timespan, resolution):
    """Load ONLY essential data for 10-second target"""
    try:
        print("=" * 60)
        print("EXTREME SPEED LOADING - 10 SECOND TARGET")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # ONLY load absolutely essential data - NO optional data
        essential_functions = {
            'devices': load_devices
            # Removed ALL other functions for maximum speed
        }
        
        # Load ONLY essential data
        print("ğŸš€ Loading ONLY essential data...")
        org_results = parallel_data_loading(essential_functions, key, org_id=org_id)
        
        # Skip network data loading for speed - only load if absolutely necessary
        network_results = {}
        for network_id in network_ids:
            network_results[network_id] = {
                'clients_overview': {},
                'clients': [],
                'traffic': {},
                'bandwidth': [],
                'limits': [],
                'wan_bandwidth': []
            }
        
        # Skip switch ports for speed
        switch_ports = {}
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âš¡ EXTREME SPEED loading completed in {duration:.2f} seconds")
        print(f"ğŸ“Š Performance: {len(network_ids)} networks, {len(essential_functions)} essential functions")
        print(f"ğŸ¯ Target: 10 seconds | Actual: {duration:.2f} seconds | {'âœ… SUCCESS' if duration <= 10 else 'âŒ NEEDS OPTIMIZATION'}")
        print("=" * 60)
        
        return {
            'org_data': org_results,
            'network_data': network_results,
            'switch_ports': switch_ports,
            'load_time': duration,
            'performance_metrics': {
                'networks_processed': len(network_ids),
                'essential_functions_processed': len(essential_functions),
                'total_api_calls': len(essential_functions),  # Only 1 API call!
                'avg_time_per_call': duration / len(essential_functions) if len(essential_functions) > 0 else 0
            }
        }
        
    except Exception as e:
        print(f"ğŸ’¥ Error in extreme speed loading: {e}")
        print("=" * 60)
        st.error(f"Failed to load dashboard data: {e}")
        return {
            'org_data': {},
            'network_data': {},
            'switch_ports': {},
            'load_time': 0,
            'performance_metrics': {}
        }

# Load organization licensing entitlements
@st.cache_data(ttl=3600)
def load_licensing_entitlements(key):
    """Load available licensing entitlements"""
    try:
        api = init_api(key)
        if not api:
            return []
        
        entitlements = api.organizations.getOrganizationLicensingSubscriptionEntitlements()
        return entitlements
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.write(f"Could not load licensing entitlements: {e}")
        return []

# Load organization subscriptions
@st.cache_data(ttl=3600)
def load_licensing_subscriptions(key):
    """Load organization subscriptions"""
    try:
        api = init_api(key)
        if not api:
            return []
        
        subscriptions = api.organizations.getOrganizationLicensingSubscriptionSubscriptions()
        return subscriptions
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.write(f"Could not load subscriptions: {e}")
        return []

# Load networks without filtering
@st.cache_data(ttl=300)
def load_networks(key, org_id):
    """Load all networks without filtering"""
    try:
        print("=" * 60)
        print("NETWORK LOADING PROCESS START (NO FILTERING)")
        print("=" * 60)
        
        api = init_api(key)
        if not api:
            print("âŒ Failed to initialize API")
            print("=" * 60)
            return []
        
        # Get all networks
        print("ğŸ“‹ Getting all networks...")
        all_networks = api.organizations.getOrganizationNetworks(org_id)
        print(f"ğŸ“Š Found {len(all_networks)} total networks")
        
        print("\n" + "=" * 60)
        print("NETWORK LOADING SUMMARY (NO FILTERING)")
        print("=" * 60)
        print(f"Total networks: {len(all_networks)}")
        print("=" * 60)
        
        return all_networks
        
    except Exception as e:
        print(f"ğŸ’¥ Error in load_networks: {e}")
        print("=" * 60)
        st.error(f"Failed to load networks: {e}")
        return []

# Load device statuses with full pagination support
@st.cache_data(ttl=180)
def load_devices(key, org_id):
    try:
        api = init_api(key)
        if not api:
            return []
        
        all_devices = []
        
        # First request with perPage=1000 (maximum allowed)
        devices = api.organizations.getOrganizationDevicesStatuses(org_id, perPage=1000)
        all_devices.extend(devices)
        
        # If we got exactly 1000 devices, there might be more - implement pagination
        while len(devices) == 1000:
            try:
                # Get next page using the last device as starting point
                last_device_serial = devices[-1].get('serial', '')
                devices = api.organizations.getOrganizationDevicesStatuses(
                    org_id, 
                    perPage=1000,
                    startingAfter=last_device_serial
                )
                if devices:
                    all_devices.extend(devices)
                else:
                    break
            except Exception as pagination_error:
                # If pagination fails, just use what we have
                if SHOW_DEBUG_INFO:
                    st.warning(f"Pagination failed, using {len(all_devices)} devices: {pagination_error}")
                break
        
        if SHOW_DEBUG_INFO:
            st.info(f"Loaded {len(all_devices)} total devices from organization")
        
        return all_devices
        
    except Exception as e:
        st.error(f"Failed to load devices: {e}")
        return []

# ULTRA-FAST device details loading - optimized for speed
@st.cache_data(ttl=60)  # Reduced TTL for faster updates
def load_device_details(key, org_id):
    """Load device details with minimal API calls for maximum speed"""
    try:
        print("ğŸš€ ULTRA-FAST device details loading...")
        start_time = datetime.now()
        
        api = init_api(key)
        if not api:
            return []
        
        # ONLY get device statuses (includes most essential info)
        # Skip getOrganizationDevices call to save time
        device_statuses = api.organizations.getOrganizationDevicesStatuses(org_id, perPage=1000)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âš¡ Device details loaded in {duration:.2f} seconds ({len(device_statuses)} devices)")
        
        return device_statuses
    except Exception as e:
        print(f"ğŸ’¥ Error loading device details: {e}")
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load device details: {e}")
        return []

# ULTRA-FAST device firmware loading - optimized for speed
@st.cache_data(ttl=300)  # Reduced TTL for faster updates
def load_device_firmware(key, org_id):
    """Load device firmware information with minimal API calls"""
    try:
        print("ğŸš€ ULTRA-FAST firmware loading...")
        start_time = datetime.now()
        
        api = init_api(key)
        if not api:
            return {}
        
        # Get firmware information for all devices
        firmware_info = api.organizations.getOrganizationFirmwareUpgrades(org_id)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âš¡ Firmware loaded in {duration:.2f} seconds")
        
        return firmware_info
    except Exception as e:
        print(f"ğŸ’¥ Error loading firmware: {e}")
        if SHOW_DEBUG_INFO:
            st.write(f"Could not load firmware info: {e}")
        return {}

# Load device performance metrics
@st.cache_data(ttl=300)
def load_device_performance(key, org_id, device_serial):
    """Load performance metrics for a specific device"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        # Get device performance data
        performance = api.organizations.getOrganizationDevicesUplinksLossAndLatency(
            organizationId=org_id,
            serials=[device_serial],
            timespan=3600  # Last hour
        )
        return performance
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.write(f"Could not load performance for {device_serial}: {e}")
        return {}

# Load network traffic data - Using actual Meraki API endpoints
@st.cache_data(ttl=300)
def load_traffic(key, network_id, timespan):
    """Load network traffic data using actual Meraki API"""
    try:
        api = init_api(key)
        if api:
            # Use the actual Meraki API endpoint for network traffic
            return api.networks.getNetworkTraffic(network_id, timespan=timespan)
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load traffic data: {e}")
        return []

# Load comprehensive traffic data from all device types
@st.cache_data(ttl=300)
def load_comprehensive_traffic(key, network_id, timespan):
    """Load traffic data from all device types and combine them"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        # Check if timespan exceeds Meraki API limits (30 days = 2592000 seconds)
        max_timespan = 2592000  # 30 days in seconds
        if timespan > max_timespan:
            if SHOW_DEBUG_INFO:
                st.warning(f"âš ï¸ ìš”ì²­ëœ ì‹œê°„ ë²”ìœ„({timespan/86400:.1f}ì¼)ê°€ Meraki API ìµœëŒ€ ì œí•œ(30ì¼)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. 30ì¼ë¡œ ì œí•œí•©ë‹ˆë‹¤.")
            timespan = max_timespan
        
        device_types = ['combined', 'wireless', 'switch', 'appliance']
        traffic_data = {}
        
        for device_type in device_types:
            try:
                # Get traffic data for each device type
                data = api.networks.getNetworkTraffic(
                    network_id, 
                    timespan=timespan,
                    deviceType=device_type
                )
                traffic_data[device_type] = data if data else []
                
                if SHOW_DEBUG_INFO:
                    st.write(f"ğŸ“Š {device_type.upper()}: {len(data) if data else 0} applications")
                    
            except Exception as e:
                if SHOW_DEBUG_INFO:
                    st.error(f"Failed to load {device_type} traffic: {e}")
                traffic_data[device_type] = []
        
        # If no data from any device type, try alternative approach
        if not any(traffic_data.values()):
            if SHOW_DEBUG_INFO:
                st.warning("âš ï¸ ëª¨ë“  ë””ë°”ì´ìŠ¤ íƒ€ì…ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²•ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
            # Try with shorter timespan for 30-day requests
            if timespan >= 2592000:  # 30 days
                shorter_timespan = 604800  # 7 days
                if SHOW_DEBUG_INFO:
                    st.info(f"ğŸ”„ 7ì¼ ë°ì´í„°ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                
                for device_type in device_types:
                    try:
                        data = api.networks.getNetworkTraffic(
                            network_id, 
                            timespan=shorter_timespan,
                            deviceType=device_type
                        )
                        traffic_data[device_type] = data if data else []
                        
                        if SHOW_DEBUG_INFO:
                            st.write(f"ğŸ“Š {device_type.upper()} (7ì¼): {len(data) if data else 0} applications")
                            
                    except Exception as e:
                        if SHOW_DEBUG_INFO:
                            st.error(f"Failed to load {device_type} traffic (7ì¼): {e}")
                        traffic_data[device_type] = []
        
        return traffic_data
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load comprehensive traffic data: {e}")
        return {}

# Parallel traffic analysis data loading - Ultra-fast TTL
@st.cache_data(ttl=10, show_spinner="íŠ¸ë˜í”½ ë°ì´í„° ë¡œë”© ì¤‘...")
def load_traffic_analysis_data_parallel(key, network_ids, timespan, resolution):
    """Load all traffic analysis data in parallel"""
    try:
        print("=" * 60)
        print("PARALLEL TRAFFIC ANALYSIS DATA LOADING START")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # Prepare API calls for all networks
        api_calls = []
        
        for network_id in network_ids:
            # Traffic data calls
            api_calls.extend([
                {
                    'key': f'traffic_{network_id}',
                    'func': load_comprehensive_traffic,
                    'args': [key, network_id, timespan]
                },
                {
                    'key': f'app_traffic_{network_id}',
                    'func': load_app_traffic,
                    'args': [key, network_id, timespan]
                },
                {
                    'key': f'bandwidth_{network_id}',
                    'func': load_net_bw,
                    'args': [key, network_id, timespan, resolution]
                },
                {
                    'key': f'wan_bandwidth_{network_id}',
                    'func': load_wan_bandwidth,
                    'args': [key, network_id, timespan, resolution]
                },
                {
                    'key': f'limits_{network_id}',
                    'func': load_limits,
                    'args': [key, network_id]
                }
            ])
        
        # Execute all calls in parallel with maximum workers for speed
        results = parallel_api_calls(api_calls, max_workers=100)
        
        # Organize results by network
        organized_results = {}
        for network_id in network_ids:
            organized_results[network_id] = {
                'traffic': results.get(f'traffic_{network_id}', {}),
                'app_traffic': results.get(f'app_traffic_{network_id}', []),
                'bandwidth': results.get(f'bandwidth_{network_id}', []),
                'wan_bandwidth': results.get(f'wan_bandwidth_{network_id}', []),
                'limits': results.get(f'limits_{network_id}', [])
            }
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"â±ï¸  Traffic analysis parallel loading completed in {duration:.2f} seconds")
        print("=" * 60)
        
        return {
            'network_data': organized_results,
            'load_time': duration
        }
        
    except Exception as e:
        print(f"ğŸ’¥ Error in parallel traffic analysis loading: {e}")
        print("=" * 60)
        st.error(f"Failed to load traffic analysis data: {e}")
        return {
            'network_data': {},
            'load_time': 0
        }

# Combine traffic data from all device types
def combine_traffic_data(traffic_data):
    """Combine traffic data from all device types into a single dataset"""
    if not traffic_data:
        return pd.DataFrame()

    combined_data = []

    for device_type, data in traffic_data.items():
        if data:
            for item in data:
                # Add device type to each item
                item_copy = item.copy()
                item_copy['deviceType'] = device_type
                combined_data.append(item_copy)

    if not combined_data:
        return pd.DataFrame()

    try:
        # Convert to DataFrame and aggregate by application
        df = pd.DataFrame(combined_data)
        
        # Check if we have the required columns
        required_columns = ['application', 'sent', 'recv', 'numClients']
        if not all(col in df.columns for col in required_columns):
            return pd.DataFrame()
        
        # Group by application and sum the values with error handling
        agg_dict = {
            'sent': 'sum',
            'recv': 'sum', 
            'numClients': 'sum'
        }
        
        if 'activeTime' in df.columns:
            agg_dict['activeTime'] = 'sum'
        if 'flows' in df.columns:
            agg_dict['flows'] = 'sum'
        if 'deviceType' in df.columns:
            agg_dict['deviceType'] = lambda x: ', '.join(sorted([str(v) for v in x.unique() if v is not None and str(v) != 'nan']))
        if 'protocol' in df.columns:
            agg_dict['protocol'] = lambda x: ', '.join(sorted([str(v) for v in x.unique() if v is not None and str(v) != 'nan']))
        if 'port' in df.columns:
            agg_dict['port'] = lambda x: ', '.join(map(str, sorted([v for v in x.unique() if v is not None and str(v) != 'nan'])))
        if 'destination' in df.columns:
            agg_dict['destination'] = lambda x: ', '.join(sorted([str(v) for v in x.unique() if v is not None and str(v) != 'nan']))
        
        aggregated = df.groupby('application').agg(agg_dict).reset_index()
        
        return aggregated
        
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Error in combine_traffic_data: {e}")
        return pd.DataFrame()

# Load network bandwidth usage history
@st.cache_data(ttl=300)
def load_network_bandwidth(key, network_id, timespan):
    """Load network bandwidth usage history"""
    try:
        api = init_api(key)
        if api:
            # Use network bandwidth usage history API
            return api.networks.getNetworkClientsBandwidthUsageHistory(
                network_id, 
                timespan=timespan, 
                resolution=300  # 5-minute resolution
            )
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load bandwidth data: {e}")
        return []

# Load application traffic (separate function for app-specific analysis)
@st.cache_data(ttl=300)
def load_app_traffic(key, network_id, timespan):
    """Load application-specific traffic data"""
    try:
        api = init_api(key)
        if api:
            return api.networks.getNetworkTraffic(network_id, timespan=timespan)
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load application traffic data: {e}")
        return []

# Load network clients with usage data
@st.cache_data(ttl=300)
def load_network_clients(key, network_id):
    """Load network clients with usage information - fetches all clients (up to 5000)"""
    try:
        api = init_api(key)
        if api:
            # Use perPage=5000 to get all clients instead of default 10
            return api.networks.getNetworkClients(network_id, perPage=5000)
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load network clients: {e}")
        return []

# Parallel client analysis data loading - Ultra-fast TTL
@st.cache_data(ttl=10, show_spinner="í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
def load_client_analysis_data_parallel(key, network_ids, timespan, resolution):
    """Load all client analysis data in parallel"""
    try:
        print("=" * 60)
        print("PARALLEL CLIENT ANALYSIS DATA LOADING START")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # Prepare API calls for all networks
        api_calls = []
        
        for network_id in network_ids:
            # Client data calls
            api_calls.extend([
                {
                    'key': f'clients_{network_id}',
                    'func': load_network_clients,
                    'args': [key, network_id]
                },
                {
                    'key': f'clients_overview_{network_id}',
                    'func': load_network_clients_overview,
                    'args': [key, network_id]
                },
                {
                    'key': f'bandwidth_{network_id}',
                    'func': load_net_bw,
                    'args': [key, network_id, timespan, resolution]
                }
            ])
        
        # Execute all calls in parallel with maximum workers for speed
        results = parallel_api_calls(api_calls, max_workers=100)
        
        # Organize results by network
        organized_results = {}
        for network_id in network_ids:
            organized_results[network_id] = {
                'clients': results.get(f'clients_{network_id}', []),
                'clients_overview': results.get(f'clients_overview_{network_id}', {}),
                'bandwidth': results.get(f'bandwidth_{network_id}', [])
            }
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"â±ï¸  Client analysis parallel loading completed in {duration:.2f} seconds")
        print("=" * 60)
        
        return {
            'network_data': organized_results,
            'load_time': duration
        }
        
    except Exception as e:
        print(f"ğŸ’¥ Error in parallel client analysis loading: {e}")
        print("=" * 60)
        st.error(f"Failed to load client analysis data: {e}")
        return {
            'network_data': {},
            'load_time': 0
        }

# Load network clients overview for total count
@st.cache_data(ttl=300)
def load_network_clients_overview(key, network_id):
    """Load network clients overview for total count and summary"""
    try:
        api = init_api(key)
        if api:
            return api.networks.getNetworkClientsOverview(network_id)
        return {}
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load network clients overview: {e}")
        return {}

# Load network bandwidth history
@st.cache_data(ttl=300)
def load_net_bw(key, network_id, timespan, resolution):
    try:
        api = init_api(key)
        if api:
            return api.networks.getNetworkClientsBandwidthUsageHistory(
                network_id, timespan=timespan, resolution=resolution
            )
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load bandwidth data: {e}")
        return []

# Load traffic shaping limits
@st.cache_data(ttl=300)
def load_limits(key, network_id):
    try:
        api = init_api(key)
        if api:
            return api.networks.getNetworkApplianceTrafficShapingUplinkBandwidth(network_id)
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load traffic limits: {e}")
        return []

# Load switch port data
@st.cache_data(ttl=300)
def load_switch_ports(key, org_id):
    try:
        dash = init_api(key)
        if not dash:
            return {}
        
        devices = dash.organizations.getOrganizationDevices(org_id)
        switches = [d for d in devices if d.get("productType") == "switch"]
        out = {}
        
        for sw in switches:
            try:
                ports = dash.switch.getDeviceSwitchPorts(sw["serial"])
                statuses = dash.switch.getDeviceSwitchPortsStatuses(sw["serial"])
                combined = []
                
                for p in ports:
                    sid = p["portId"]
                    info = next((s for s in statuses if s["portId"] == sid), {})
                    combined.append({**p, **info})
                
                out[sw["name"]] = combined
            except Exception as e:
                if SHOW_DEBUG_INFO:
                    st.warning(f"Failed to load ports for switch {sw['name']}: {e}")
                continue
                
        return out
    except Exception as e:
        st.error(f"Failed to load switch ports: {e}")
        return {}

# Load WAN uplink bandwidth data
@st.cache_data(ttl=300)
def load_wan_bandwidth(key, network_id, timespan, resolution):
    try:
        api = init_api(key)
        if not api:
            return []
        
        # Get WAN uplink bandwidth data
        bandwidth_data = api.networks.getNetworkUplinkBandwidthUsage(network_id, timespan=timespan, resolution=resolution)
        
        if SHOW_DEBUG_INFO:
            st.write(f"ğŸ” Debug: Bandwidth Data Structure")
            st.write(f"Data entries: {len(bandwidth_data)}")
            if bandwidth_data:
                st.write(f"First entry structure: {list(bandwidth_data[0].keys())}")
        
        return bandwidth_data
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load WAN bandwidth data: {e}")
        return []

# Load device status events and alerts
@st.cache_data(ttl=300)
def load_device_alerts(key, org_id, device_serial, timespan=86400):
    """Load detailed alert information for a specific device"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        alerts = {}
        
        # Get device status events (last 24 hours by default)
        try:
            events = api.organizations.getOrganizationDevicesStatusesHistory(
                organizationId=org_id,
                serials=[device_serial],
                timespan=timespan
            )
            if events:
                alerts['status_events'] = events
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load status events: {e}")
        
        # Get device performance metrics
        try:
            performance = api.organizations.getOrganizationDevicesUplinksLossAndLatency(
                organizationId=org_id,
                serials=[device_serial],
                timespan=timespan
            )
            if performance:
                alerts['performance'] = performance
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load performance data: {e}")
        
        # Get device security events (if available)
        try:
            security = api.organizations.getOrganizationDevicesSecurityEvents(
                organizationId=org_id,
                serials=[device_serial],
            )
            if security:
                alerts['security'] = security
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load security events: {e}")
        
        return alerts
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load device alerts: {e}")
        return {}

# Parallel device alerts data loading - Ultra-fast TTL
@st.cache_data(ttl=10, show_spinner="ë””ë°”ì´ìŠ¤ ì•Œë¦¼ ë°ì´í„° ë¡œë”© ì¤‘...")
def load_device_alerts_data_parallel(key, org_id, device_serials, timespan=86400):
    """Load device alerts data for multiple devices in parallel"""
    try:
        print("=" * 60)
        print("PARALLEL DEVICE ALERTS DATA LOADING START")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # Prepare API calls for all devices
        api_calls = []
        
        for device_serial in device_serials:
            # Device-specific alert calls
            api_calls.extend([
                {
                    'key': f'status_events_{device_serial}',
                    'func': lambda api, org_id, serial, timespan: api.organizations.getOrganizationDevicesStatusesHistory(
                        organizationId=org_id,
                        serials=[serial],
                        timespan=timespan
                    ),
                    'args': [key, org_id, device_serial, timespan]
                },
                {
                    'key': f'performance_{device_serial}',
                    'func': lambda api, org_id, serial, timespan: api.organizations.getOrganizationDevicesUplinksLossAndLatency(
                        organizationId=org_id,
                        serials=[serial],
                        timespan=timespan
                    ),
                    'args': [key, org_id, device_serial, timespan]
                },
                {
                    'key': f'security_{device_serial}',
                    'func': lambda api, org_id, serial: api.organizations.getOrganizationDevicesSecurityEvents(
                        organizationId=org_id,
                        serials=[serial]
                    ),
                    'args': [key, org_id, device_serial]
                }
            ])
        
        # Execute all calls in parallel with maximum workers for speed
        results = parallel_api_calls(api_calls, max_workers=100)
        
        # Organize results by device
        organized_results = {}
        for device_serial in device_serials:
            organized_results[device_serial] = {
                'status_events': results.get(f'status_events_{device_serial}', []),
                'performance': results.get(f'performance_{device_serial}', []),
                'security': results.get(f'security_{device_serial}', [])
            }
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"â±ï¸  Device alerts parallel loading completed in {duration:.2f} seconds")
        print("=" * 60)
        
        return {
            'device_data': organized_results,
            'load_time': duration
        }
        
    except Exception as e:
        print(f"ğŸ’¥ Error in parallel device alerts loading: {e}")
        print("=" * 60)
        st.error(f"Failed to load device alerts data: {e}")
        return {
            'device_data': {},
            'load_time': 0
        }

# Load organization configuration changes
@st.cache_data(ttl=300)
def load_configuration_changes(key, org_id, per_page=100):
    """Load organization configuration changes"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        # Get configuration changes
        try:
            changes = api.organizations.getOrganizationConfigurationChanges(
                organizationId=org_id,
                perPage=per_page
            )
            return changes
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load configuration changes: {e}")
            return {}
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load configuration changes: {e}")
        return {}

# Load organization license overview - Enhanced with better error handling
@st.cache_data(ttl=60)  # Reduced TTL for faster updates
def load_license_overview(key, org_id):
    """Load organization license overview with enhanced error handling"""
    try:
        print("=" * 60)
        print("LICENSE OVERVIEW LOADING START")
        print("=" * 60)
        print(f"Organization ID: {org_id}")
        
        api = init_api(key)
        if not api:
            print("âŒ Failed to initialize API")
            return {}
        
        # Try multiple API endpoints for license information
        license_data = {}
        
        # Method 1: Try getOrganizationLicensesOverview
        try:
            print("ğŸ” Trying getOrganizationLicensesOverview...")
            overview = api.organizations.getOrganizationLicensesOverview(organizationId=org_id)
            if overview:
                license_data.update(overview)
                print("âœ… getOrganizationLicensesOverview successful")
            else:
                print("âš ï¸ getOrganizationLicensesOverview returned empty")
        except Exception as e:
            print(f"âŒ getOrganizationLicensesOverview failed: {e}")
        
        # Method 2: Try getOrganizationLicensingCotermLicenses
        try:
            print("ğŸ” Trying getOrganizationLicensingCotermLicenses...")
            coterm_licenses = api.organizations.getOrganizationLicensingCotermLicenses(organizationId=org_id)
            if coterm_licenses:
                license_data['coterm_licenses'] = coterm_licenses
                print("âœ… getOrganizationLicensingCotermLicenses successful")
            else:
                print("âš ï¸ getOrganizationLicensingCotermLicenses returned empty")
        except Exception as e:
            print(f"âŒ getOrganizationLicensingCotermLicenses failed: {e}")
        
        # Method 3: Try getOrganizationLicensingCotermLicensesOverview
        try:
            print("ğŸ” Trying getOrganizationLicensingCotermLicensesOverview...")
            coterm_overview = api.organizations.getOrganizationLicensingCotermLicensesOverview(organizationId=org_id)
            if coterm_overview:
                license_data.update(coterm_overview)
                print("âœ… getOrganizationLicensingCotermLicensesOverview successful")
            else:
                print("âš ï¸ getOrganizationLicensingCotermLicensesOverview returned empty")
        except Exception as e:
            print(f"âŒ getOrganizationLicensingCotermLicensesOverview failed: {e}")
        
        print("=" * 60)
        print("LICENSE OVERVIEW LOADING COMPLETE")
        print("=" * 60)
        print(f"Final license data: {license_data}")
        print("=" * 60)
        
        return license_data
        
    except Exception as e:
        print(f"ğŸ’¥ Error in load_license_overview: {e}")
        print("=" * 60)
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load license overview: {e}")
        return {}


# Helper function to parse date format
def parse_date(date_string):
    """Parse ISO 8601 date string and return readable format"""
    if not date_string or date_string == 'N/A':
        return 'N/A'
    
    try:
        from datetime import datetime
        # Parse ISO 8601 format (2016-01-07T20:35:14Z)
        if 'T' in date_string and date_string.endswith('Z'):
            # Remove Z and parse
            date_string = date_string[:-1]
            dt = datetime.fromisoformat(date_string)
            # Return formatted date (YYYY-MM-DD HH:MM:SS)
            return dt.strftime('%Y-%m-%d %H:%M:%S')
        else:
            return date_string
    except Exception:
        return date_string

# Load organization detailed licenses
@st.cache_data(ttl=300)
def load_detailed_licenses(key, org_id, per_page=100):
    """Load organization detailed license information"""
    try:
        api = init_api(key)
        if not api:
            return []
        
        # Get detailed licenses using direct HTTP request
        try:
            import requests
            
            # API endpoint and headers
            url = f"https://api.meraki.com/api/v1/organizations/{org_id}/licensing/coterm/licenses"
            headers = {
                'X-Cisco-Meraki-API-Key': key,
                'Accept': 'application/json'
            }
            params = {
                'perPage': per_page
            }
            
            # CLI Debug output for API call
            print("=" * 50)
            print("LICENSE API CALL DEBUG")
            print("=" * 50)
            print(f"API URL: {url}")
            print(f"Headers: {headers}")
            print(f"Params: {params}")
            print("=" * 50)
            
            # Make HTTP request
            response = requests.get(url, headers=headers, params=params)
            
            # CLI Debug output for response
            print("=" * 50)
            print("LICENSE API RESPONSE DEBUG")
            print("=" * 50)
            print(f"Status Code: {response.status_code}")
            print(f"Response Headers: {dict(response.headers)}")
            print(f"Response Type: {type(response.json()) if response.status_code == 200 else 'Error'}")
            
            if response.status_code == 200:
                licenses = response.json()
                print(f"Response Length: {len(licenses) if licenses else 'None'}")
                print("\nFull API Response:")
                print(licenses)
                print("=" * 50)
                return licenses
            else:
                print(f"Error Response: {response.text}")
                print("=" * 50)
                return []
                
        except Exception as e:
            print("=" * 50)
            print("LICENSE API ERROR DEBUG")
            print("=" * 50)
            print(f"Organization ID: {org_id}")
            print(f"Per Page: {per_page}")
            print(f"Error: {e}")
            print(f"Error Type: {type(e)}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            print("=" * 50)
            
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load detailed licenses: {e}")
                st.write(f"Error type: {type(e)}")
                st.write(f"Traceback: {traceback.format_exc()}")
            return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load detailed licenses: {e}")
        return []

# Load network-wide alerts
@st.cache_data(ttl=300)
def load_network_alerts(key, network_id, timespan=86400):
    """Load network-wide alerts and events"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        alerts = {}
        
        # Get network events
        try:
            events = api.networks.getNetworkEvents(
                networkId=network_id,
                timespan=timespan,
                eventTypes=['alert', 'warning', 'error']
            )
            if events:
                alerts['network_events'] = events
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load network events: {e}")
        
        # Get network health alerts
        try:
            health = api.networks.getNetworkHealthAlerts(networkId=network_id)
            if health:
                alerts['health_alerts'] = health
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.write(f"Could not load health alerts: {e}")
        
        return alerts
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load network alerts: {e}")
        return {}

# Load all network clients
@st.cache_data(ttl=300)
def get_all_network_clients(key, network_id):
    """Load all network clients with perPage=5000 to get complete list"""
    try:
        api = init_api(key)
        if api:
            # Use perPage=5000 to get all clients instead of default 10
            return api.networks.getNetworkClients(network_id, perPage=5000)
        return []
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load network clients: {e}")
        return []

# Load client usage histories for all clients
@st.cache_data(ttl=300)
def get_clients_usage_histories(key, network_id, timespan, resolution):
    try:
        api = init_api(key)
        if not api:
            return []
        
        # Get all clients first
        clients = get_all_network_clients(key, network_id)
        if not clients:
            return []
        
        # Extract MAC addresses
        mac_addresses = [client['mac'] for client in clients if 'mac' in client]
        
        if not mac_addresses:
            return []
        
        # Process in chunks of 50 (Meraki API limit)
        chunk_size = 50
        all_results = []
        
        for i in range(0, len(mac_addresses), chunk_size):
            chunk = mac_addresses[i:i + chunk_size]
            try:
                chunk_results = api.networks.getNetworkClientsBandwidthUsageHistory(
                    network_id, 
                    timespan=timespan, 
                    resolution=resolution,
                    macs=chunk
                )
                all_results.extend(chunk_results)
            except Exception as e:
                if SHOW_DEBUG_INFO:
                    st.warning(f"Failed to load bandwidth history for chunk {i//chunk_size + 1}: {e}")
                continue
        
        return all_results
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load client usage histories: {e}")
        return []

# Load device system information (OS version, power status, CPU)
@st.cache_data(ttl=300)
def load_device_system_info(key, network_id, device_serial):
    """Load detailed system information for a specific device"""
    try:
        api = init_api(key)
        if not api:
            return {}
        
        system_info = {}
        
        # Try to get device status (includes power and basic info)
        try:
            device_status = api.devices.getDeviceStatus(device_serial)
            system_info['status'] = device_status
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.warning(f"Could not load device status for {device_serial}: {e}")
        
        # Try to get device management interface (includes OS version)
        try:
            mgmt_interface = api.devices.getDeviceManagementInterface(device_serial)
            system_info['management'] = mgmt_interface
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.warning(f"Could not load management interface for {device_serial}: {e}")
        
        # Try to get device performance (includes CPU if available)
        try:
            performance = api.devices.getDevicePerformance(device_serial)
            system_info['performance'] = performance
        except Exception as e:
            if SHOW_DEBUG_INFO:
                st.warning(f"Could not load performance data for {device_serial}: {e}")
        
        return system_info
        
    except Exception as e:
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load device system info for {device_serial}: {e}")
        return {}

# Load device events for event log
@st.cache_data(ttl=60)  # Shorter cache for events
def load_device_events(key, network_id, device_serial, product_type=None, timespan=86400):
    """Load events for a specific device"""
    try:
        api = init_api(key)
        if not api:
            print(f"âŒ API ì´ˆê¸°í™” ì‹¤íŒ¨ - device_serial: {device_serial}")
            return []
        
        # Get network events filtered by device serial and product type
        # API í˜•ì‹: /networks/:networkId/events?productType={{productType}}&deviceSerial={{deviceSerial}}&perPage={{perPage}}
        params = {
            'deviceSerial': device_serial,  # deviceSericalì´ ì•„ë‹Œ deviceSerial
            'perPage': 1000  # Get up to 1000 events
        }
        
        # Add product type if available (first parameter in your format)
        if product_type:
            params['productType'] = product_type
        
        # Add timespan (24 hours default)
        params['timespan'] = timespan
        
        # Print API call information to console
        print(f"\nğŸ” ì´ë²¤íŠ¸ ë¡œê·¸ API í˜¸ì¶œ:")
        print(f"   ğŸ“¡ API URL: https://api.meraki.com/api/v1/networks/{network_id}/events")
        print(f"   ğŸ“‹ Parameters (ìˆœì„œ: productType, deviceSerial, perPage):")
        if 'productType' in params:
            print(f"      - productType: {params['productType']}")
        print(f"      - deviceSerial: {params['deviceSerial']}")
        print(f"      - perPage: {params['perPage']}")
        print(f"      - timespan: {params['timespan']}")
        print(f"   ğŸŒ Network ID: {network_id}")
        print(f"   ğŸ”§ Device Serial: {device_serial}")
        print(f"   ğŸ“± Product Type: {product_type}")
        print(f"   â±ï¸ Timespan: {timespan} seconds ({timespan/3600:.1f} hours)")
        
        # Construct full URL for debugging
        param_string = "&".join([f"{k}={v}" for k, v in params.items()])
        full_url = f"https://api.meraki.com/api/v1/networks/{network_id}/events?{param_string}"
        print(f"   ğŸ”— Full URL: {full_url}")
        
        # Make the API call
        print(f"   ğŸš€ API í˜¸ì¶œ ì¤‘...")
        events = api.networks.getNetworkEvents(network_id, **params)
        
        # Print response information
        if events is None:
            print(f"   âŒ API ì‘ë‹µ: None")
            print(f"   ğŸ”„ ëŒ€ì²´ ë°©ë²• ì‹œë„: deviceSerial ì—†ì´ í˜¸ì¶œ...")
            
            # Try without deviceSerial filter as fallback
            try:
                fallback_params = {'timespan': timespan, 'perPage': 1000}
                if product_type:
                    fallback_params['productType'] = product_type
                print(f"   ğŸ“‹ ëŒ€ì²´ Parameters: {fallback_params}")
                
                events = api.networks.getNetworkEvents(network_id, **fallback_params)
                if events:
                    if isinstance(events, list):
                        # Filter by device serial manually
                        filtered_events = [e for e in events if isinstance(e, dict) and e.get('deviceSerial') == device_serial]
                        print(f"   âœ… ëŒ€ì²´ í˜¸ì¶œ ì„±ê³µ: ì „ì²´ {len(events)}ê°œ ì¤‘ {len(filtered_events)}ê°œ í•„í„°ë§ë¨")
                        return filtered_events
                    elif isinstance(events, dict) and 'events' in events:
                        # Extract events from dict response
                        events_list = events['events']
                        if isinstance(events_list, list):
                            filtered_events = [e for e in events_list if isinstance(e, dict) and e.get('deviceSerial') == device_serial]
                            print(f"   âœ… ëŒ€ì²´ í˜¸ì¶œ ì„±ê³µ (Dict): ì „ì²´ {len(events_list)}ê°œ ì¤‘ {len(filtered_events)}ê°œ í•„í„°ë§ë¨")
                            return filtered_events
                        else:
                            print(f"   âŒ ëŒ€ì²´ í˜¸ì¶œ: events í‚¤ì˜ ê°’ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜")
                            return []
                    else:
                        print(f"   âŒ ëŒ€ì²´ í˜¸ì¶œ: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ íƒ€ì… {type(events)}")
                        return []
                else:
                    print(f"   âŒ ëŒ€ì²´ í˜¸ì¶œë„ ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ")
                    return []
            except Exception as fallback_error:
                print(f"   ğŸ’¥ ëŒ€ì²´ í˜¸ì¶œ ì‹¤íŒ¨: {fallback_error}")
                return []
            
        elif isinstance(events, list):
            print(f"   âœ… API ì‘ë‹µ: {len(events)}ê°œ ì´ë²¤íŠ¸ ë°˜í™˜")
            if len(events) > 0:
                print(f"   ğŸ“„ ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ìƒ˜í”Œ:")
                first_event = events[0]
                if isinstance(first_event, dict):
                    for key, value in list(first_event.items())[:5]:  # First 5 keys
                        print(f"      - {key}: {value}")
                    if len(first_event) > 5:
                        print(f"      ... (ì´ {len(first_event)}ê°œ í•„ë“œ)")
                    
                    # Check if events are actually for this device
                    device_match = first_event.get('deviceSerial') == device_serial
                    print(f"   ğŸ¯ ë””ë°”ì´ìŠ¤ ë§¤ì¹­: {device_match} (ì°¾ëŠ” ì‹œë¦¬ì–¼: {device_serial}, ì‹¤ì œ: {first_event.get('deviceSerial', 'N/A')})")
                else:
                    print(f"      íƒ€ì…: {type(first_event)}, ê°’: {str(first_event)[:100]}")
            return events
        elif isinstance(events, dict):
            print(f"   ğŸ“¦ API ì‘ë‹µ: Dict í˜•íƒœ (Meraki API v1 í˜•ì‹)")
            print(f"   ğŸ” ì‘ë‹µ êµ¬ì¡°:")
            for key, value in events.items():
                if key == 'events':
                    if isinstance(value, list):
                        print(f"      - {key}: {len(value)}ê°œ ì´ë²¤íŠ¸ (ë¦¬ìŠ¤íŠ¸)")
                    else:
                        print(f"      - {key}: {type(value)} (ì˜ˆìƒ: ë¦¬ìŠ¤íŠ¸)")
                else:
                    print(f"      - {key}: {str(value)[:50]}...")
            
            # Extract events list from the response
            events_list = events.get('events', [])
            if isinstance(events_list, list):
                print(f"   âœ… events í‚¤ì—ì„œ {len(events_list)}ê°œ ì´ë²¤íŠ¸ ì¶”ì¶œ")
                if len(events_list) > 0:
                    print(f"   ğŸ“„ ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ìƒ˜í”Œ:")
                    first_event = events_list[0]
                    if isinstance(first_event, dict):
                        for key, value in list(first_event.items())[:5]:  # First 5 keys
                            print(f"      - {key}: {value}")
                        if len(first_event) > 5:
                            print(f"      ... (ì´ {len(first_event)}ê°œ í•„ë“œ)")
                        
                        # Check if events are actually for this device
                        device_match = first_event.get('deviceSerial') == device_serial
                        print(f"   ğŸ¯ ë””ë°”ì´ìŠ¤ ë§¤ì¹­: {device_match} (ì°¾ëŠ” ì‹œë¦¬ì–¼: {device_serial}, ì‹¤ì œ: {first_event.get('deviceSerial', 'N/A')})")
                return events_list
            else:
                print(f"   âŒ events í‚¤ì˜ ê°’ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜: {type(events_list)}")
                return []
        else:
            print(f"   âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ íƒ€ì…: {type(events)}")
            print(f"   ğŸ“ ì‘ë‹µ ë‚´ìš©: {str(events)[:200]}")
            if SHOW_DEBUG_INFO:
                st.warning(f"Unexpected events data type: {type(events)} for device {device_serial}")
            return []
        
    except Exception as e:
        print(f"   ğŸ’¥ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        print(f"   ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        if SHOW_DEBUG_INFO:
            st.error(f"Failed to load device events for {device_serial}: {e}")
        return []

# Function to generate event log text file
def generate_event_log_text(events, device_serial):
    """Generate a text file content from device events"""
    # Check if events is valid and is a list
    if not events or not isinstance(events, list):
        return f"No events found for device {device_serial}\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n" + "=" * 80 + "\n\nNo event data available."
    
    log_content = f"Event Log for Device: {device_serial}\n"
    log_content += f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    log_content += "=" * 80 + "\n\n"
    
    for i, event in enumerate(events):
        # Ensure event is a dictionary
        if not isinstance(event, dict):
            log_content += f"Event {i+1}: Invalid event data format\n"
            log_content += "-" * 40 + "\n"
            continue
            
        timestamp = event.get('occurredAt', 'N/A')
        event_type = event.get('type', 'N/A')
        description = event.get('description', 'N/A')
        category = event.get('category', 'N/A')
        
        log_content += f"Event {i+1}:\n"
        log_content += f"Timestamp: {timestamp}\n"
        log_content += f"Type: {event_type}\n"
        log_content += f"Category: {category}\n"
        log_content += f"Description: {description}\n"
        log_content += "-" * 40 + "\n"
    
    return log_content

# Security Check: Validate API Key
if not MERAKI_API_KEY:
    st.error("ğŸ” **API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**")
    st.markdown("""
    ### ì„¤ì • ë°©ë²•:
    
    1. **config.py íŒŒì¼ ìƒì„±**:
       ```bash
       cp config_example.py config.py
       ```
    
    2. **API í‚¤ ì„¤ì •**:
       ```python
       MERAKI_API_KEY = "your_actual_meraki_api_key_here"
       ```
    
    3. **Meraki API í‚¤ ë°œê¸‰**:
       - [Meraki Dashboard](https://dashboard.meraki.com) ë¡œê·¸ì¸
       - Organization > Settings > API access
       - ìƒˆ API í‚¤ ìƒì„±
    
    ### ë³´ì•ˆ ì£¼ì˜ì‚¬í•­:
    - âŒ **ì ˆëŒ€ ì½”ë“œì— API í‚¤ë¥¼ í•˜ë“œì½”ë”©í•˜ì§€ ë§ˆì„¸ìš”**
    - âœ… **config.py íŒŒì¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
    - âœ… **config.pyëŠ” .gitignoreì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤**
    """)
    st.stop()

# Main title
st.title("ğŸŒ  Meraki Network Analytics Dashboard")

# API Version and Capabilities Info - Hidden for cleaner UI
# st.markdown("""
# <div style="background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
#     <h4 style="margin: 0; color: #1f2937;">ğŸ“¡ API Information</h4>
#     <p style="margin: 0.5rem 0 0 0; color: #6b7280;">
#         <strong>Version:</strong> 1.62.0 | <strong>Base URL:</strong> https://api.meraki.com/api/v1 | 
#         <strong>Last Updated:</strong> September 3, 2025
#     </p>
#     <p style="margin: 0.5rem 0 0 0; color: #6b7280;">
#         <strong>Capabilities:</strong> Network Management â€¢ Device Configuration â€¢ Security Monitoring â€¢ 
#         Analytics & Insights â€¢ Wireless Management â€¢ Automation Tools
#     </p>
# </div>
# """, unsafe_allow_html=True)

# Log user login and start loading organizations
print("=" * 80)
print("ğŸš€ USER LOGGED IN - LOADING ORGANIZATIONS")
print("=" * 80)
print(f"User: {st.session_state.get('username', 'Unknown')}")
print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)

# Organization selection with enhanced management
try:
    orgs = load_orgs(api_key)
    print(f"âœ… Organizations loaded successfully: {len(orgs)} organizations")
except Exception as e:
    st.error(f"âŒ ì¡°ì§ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    st.warning(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
    
    st.warning("ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
    st.write("1. API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    st.write("2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    st.write("3. Meraki Dashboard API ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    st.write("4. ì´ì „ ìºì‹œ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    st.info(f"ğŸ”‘ í˜„ì¬ API í‚¤: {api_key[:10]}...{api_key[-4:]}")
    
    col1, col2 = st.columns(2)
    with col1:
        # Clear cache and retry button
        if st.button("ğŸ”„ ìºì‹œ í´ë¦¬ì–´ í›„ ì¬ì‹œë„", type="primary", use_container_width=True):
            st.cache_data.clear()
            st.cache_resource.clear()
            print("âœ… All caches cleared")
            st.success("ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘...")
            time.sleep(1)
            st.rerun()
    
    with col2:
        # Just retry button
        if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„", type="secondary", use_container_width=True):
            st.rerun()
    
    st.stop()

# Check if organizations were loaded
if not orgs or len(orgs) == 0:
    st.error("âš ï¸ ì¡°ì§ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.warning("ìºì‹œëœ ë¹ˆ ê²°ê³¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìºì‹œë¥¼ í´ë¦¬ì–´í•´ë³´ì„¸ìš”.")
    
    if st.button("ğŸ”„ ìºì‹œ í´ë¦¬ì–´ í›„ ì¬ì‹œë„", type="primary"):
        st.cache_data.clear()
        st.cache_resource.clear()
        print("âœ… All caches cleared")
        st.rerun()
    
    st.stop()

# Organization filtering - Load from config or use all organizations
try:
    from config import ALLOWED_ORGANIZATION_IDS
except ImportError:
    # If no whitelist is configured, show all organizations
    ALLOWED_ORGANIZATION_IDS = None

# Organization display - with optional filtering
print("=" * 80)
print("ORGANIZATION LOADING")
print("=" * 80)
print(f"Total organizations from API: {len(orgs)}")

org_map = {}
filtered_out = []

for o in orgs:
    org_name = o.get('name', 'Unknown')
    org_id = o.get('id', '')
    org_url = o.get('url', '')
    
    # Apply filtering if whitelist is configured
    if ALLOWED_ORGANIZATION_IDS is not None:
        if org_id in ALLOWED_ORGANIZATION_IDS:
            display_name = org_name
            org_map[display_name] = org_id
            print(f"âœ… Included: {org_name} (ID: {org_id})")
        else:
            filtered_out.append(org_name)
            print(f"âŒ Filtered: {org_name} (ID: {org_id})")
    else:
        # No filtering - include all organizations
        display_name = org_name
        org_map[display_name] = org_id
        print(f"âœ… Included: {org_name} (ID: {org_id})")

print("\n" + "=" * 80)
print("ORGANIZATION SUMMARY")
print("=" * 80)
print(f"Available organizations: {len(org_map)}")
if ALLOWED_ORGANIZATION_IDS is not None:
    print(f"Filtered out: {len(filtered_out)}")
    print("Note: Organization filtering is enabled via config")
else:
    print("Note: All organizations are shown (no filtering)")
print("=" * 80)

# Set default organization
default_org = None
default_index = 0

# Try to find default organization from config
if DEFAULT_ORGANIZATION and org_map:
    for i, org_name in enumerate(org_map.keys()):
        org_id_val = org_map[org_name]
        if org_id_val == DEFAULT_ORGANIZATION:
            default_org = org_name
            default_index = i
            break

# If default organization not found, use the first available
if not default_org and org_map:
    default_org = list(org_map.keys())[0]
    default_index = 0

# Ensure we have a valid default organization
if not org_map:
    st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ì¡°ì§ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# Update accessible organization names for auto-switching
if 'accessible_org_names' not in st.session_state or not st.session_state.accessible_org_names:
    st.session_state.accessible_org_names = list(org_map.keys())

# Organization selection with enhanced UI
col1, col2, col3 = st.columns([4, 1, 1])
with col1:
    # Initialize organization in session state if not exists
    if 'selected_organization' not in st.session_state:
        st.session_state.selected_organization = default_org
    
    sel_org = st.selectbox(r"$\textsf{\Large ğŸ¢ ì¡°ì§ ì„ íƒ}$", list(org_map.keys()), 
                       index=list(org_map.keys()).index(st.session_state.selected_organization) if st.session_state.selected_organization in org_map else default_index,
                           key="org_selection")
    
    # Update session state when organization changes
    if sel_org != st.session_state.selected_organization:
        st.session_state.selected_organization = sel_org

org_id = org_map[sel_org]

nets = load_networks(api_key, org_id)

# Debug: Show filtering results
print("=" * 80)
print("NETWORK FILTERING RESULTS")
print("=" * 80)
print(f"Total filtered networks: {len(nets)}")
for i, net in enumerate(nets, 1):
    net_name = net.get('name', 'Unknown')
    net_id = net.get('id', 'Unknown')
    device_count = net.get('device_count', 0)
    print(f"  {i}. {net_name} (ID: {net_id}) - {device_count} devices")
print("=" * 80)

if not nets:
    st.error("âš ï¸ ì´ ì¡°ì§ì—ì„œ ë””ë°”ì´ìŠ¤ê°€ ìˆëŠ” ì ‘ê·¼ ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ ë„¤íŠ¸ì›Œí¬ í•„í„°ë§ ê³¼ì •ì—ì„œ ë””ë°”ì´ìŠ¤ê°€ ì—†ê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ë„¤íŠ¸ì›Œí¬ê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# Enhanced network display with more details
net_map = {}
for n in nets:
    net_name = n.get('name', 'Unknown')
    net_id = n.get('id', '')
    net_type = n.get('type', 'Unknown')
    net_id_short = net_id[:8] + "..." if len(net_id) > 8 else net_id
    display_name = net_name
    net_map[display_name] = net_id

# Network selection with enhanced UI
col1, col2 = st.columns([3, 1])
with col1:
    # Initialize networks in session state if not exists
    if 'selected_networks' not in st.session_state:
        default_networks = list(net_map.keys())[:3] if len(net_map) > 3 else list(net_map.keys())
        st.session_state.selected_networks = default_networks
    
    # Validate that selected networks exist in current options
    current_network_options = list(net_map.keys())
    valid_selected_networks = [net for net in st.session_state.selected_networks if net in current_network_options]
    
    # If no valid networks or all networks are invalid, use default
    if not valid_selected_networks:
        valid_selected_networks = current_network_options[:3] if len(current_network_options) > 3 else current_network_options
        st.session_state.selected_networks = valid_selected_networks
    
    sel_nets_display = st.multiselect(r"$\textsf{\Large ğŸŒ ë„¤íŠ¸ì›Œí¬ ì„ íƒ (ê´€ë¦¬í•  ë„¤íŠ¸ì›Œí¬ ì„ íƒ)}$", current_network_options, 
                                     default=valid_selected_networks,
                                     key="network_selection")
    
    # Update session state when networks change
    if sel_nets_display != st.session_state.selected_networks:
        st.session_state.selected_networks = sel_nets_display
    
    sel_nets = [net_map[name] for name in sel_nets_display]

if not sel_nets:
    st.error("ìµœì†Œ í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    st.stop()

# Network management panel - DISABLED FOR CLEANER UI
# ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬ íŒ¨ë„ì„ ìˆ¨ê¹€ ì²˜ë¦¬ (UI ë‹¨ìˆœí™”ë¥¼ ìœ„í•´)
# with st.expander("ğŸŒ ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬", expanded=True):
#     col1, col2, col3 = st.columns(3)
#     
#     with col1:
#         st.markdown("**ğŸ“Š ë„¤íŠ¸ì›Œí¬ ìš”ì•½**")
#         st.write(f"**ì´ ë„¤íŠ¸ì›Œí¬:** {len(nets)}")
#         st.write(f"**ì„ íƒëœ ë„¤íŠ¸ì›Œí¬:** {len(sel_nets)}")
#         
#         # Network types breakdown
#         network_types = {}
#         for net in nets:
#             net_type = net.get('type', 'Unknown')
#             network_types[net_type] = network_types.get(net_type, 0) + 1
#         
#         st.write("**ë„¤íŠ¸ì›Œí¬ ìœ í˜•:**")
#         for net_type, count in network_types.items():
#             st.write(f"- {net_type}: {count}")
#     
#     with col2:
#         st.markdown("**ğŸ“ˆ ì„ íƒëœ ë„¤íŠ¸ì›Œí¬**")
#         for net_id in sel_nets:
#             display_name = next((name for name, nid in net_map.items() if nid == net_id), f"Network_{net_id}")
#             # Extract network name without ID suffix for cleaner display
#             network_name = display_name.split(' (')[0] if ' (' in display_name else display_name
#             st.write(f"â€¢ {network_name} (ID: {net_id})")
# VLAN Management section removed - functionality not implemented

# Create selected_networks list with all required information
# sel_nets contains network IDs, so we need to find the corresponding display names
selected_networks = []
for net_id in sel_nets:
    # Find the display name for this network ID
    display_name = next((name for name, nid in net_map.items() if nid == net_id), f"Network_{net_id}")
    selected_networks.append((net_id, display_name, "", "", ""))

# Ultra-fast device loading with immediate display
print("=" * 60)
print("ULTRA-FAST DEVICE DATA LOADING")
print("=" * 60)

# Load critical data first for immediate display (fastest possible)
print("ğŸš€ Loading critical device data for immediate display...")
devices = load_critical_data_fast(api_key, org_id)

# Filter devices for selected networks immediately
filtered = [d for d in devices if d["networkId"] in sel_nets]

print(f"âœ… Critical devices loaded: {len(devices)} (filtered: {len(filtered)})")

# Show immediate results to user
if filtered:
    print("ğŸ‰ UI can now display device data immediately!")
else:
    print("âš ï¸ No devices found for selected networks")

# ULTRA-FAST device details loading with immediate display
print("âš¡ ULTRA-FAST device details loading...")

# Load device details first (most important for UI)
print("ğŸš€ Loading device details for immediate display...")
detailed_devices = load_device_details(api_key, org_id)

# Filter detailed devices immediately
filtered_detailed = [d for d in detailed_devices if d.get("networkId") in sel_nets]

print(f"âœ… Device details loaded: {len(detailed_devices)} devices (filtered: {len(filtered_detailed)})")

# Load firmware in background (non-blocking)
print("ğŸ”„ Loading firmware in background...")
try:
    firmware_info = load_device_firmware(api_key, org_id)
    print(f"âœ… Firmware loaded: {len(firmware_info) if isinstance(firmware_info, dict) else 'N/A'}")
except Exception as e:
    print(f"âš ï¸ Firmware loading failed: {e}")
    firmware_info = {}

dashboard_data = {'org_data': {}, 'network_data': {}, 'load_time': 0}

print("ğŸ‰ UI can now display device details immediately!")

print("=" * 60)

# Verify filtered devices
print("=" * 60)
print("DEVICE FILTERING VERIFICATION")
print("=" * 60)
print(f"Total devices in organization: {len(devices)}")
print(f"Total detailed devices in organization: {len(detailed_devices)}")
print(f"Selected networks count: {len(sel_nets)}")
print(f"Filtered devices for selected networks: {len(filtered)}")
print(f"Filtered detailed devices: {len(filtered_detailed)}")
print("=" * 60)

# Display content based on selected page from sidebar navigation
current_page = st.session_state.get('current_page', 'ë©”ì¸í™”ë©´')

if current_page == "ë©”ì¸í™”ë©´":
    
    # Header with refresh button
    col1, col2 = st.columns([4, 1])
    with col1:
        st.header("ğŸ“Š ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ ìƒíƒœ")
    #with col2:
    #    st.markdown("")  # Add some spacing
    #    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", key="main_refresh", help="ë°ì´í„°ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ê²½ê³¼ì‹œê°„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"):
    #        st.session_state.data_load_time = datetime.now()
    #        st.cache_data.clear()
    #        st.rerun()
    
    # Calculate metrics by product type
    total_n = len(sel_nets)
    total_d = len(filtered)
    
    # Group devices by product type
    product_stats = {}
    product_type_map = {
        'appliance': 'ğŸ”’ Appliance',
        'switch': 'ğŸ”Œ Switch', 
        'wireless': 'ğŸ“¶ Wireless AP',
        'camera': 'ğŸ“¹ Camera',
        'sensor': 'ğŸŒ¡ï¸ Sensor',
        'cellularGateway': 'ğŸ“± Cellular Gateway'
    }
    
    for device in filtered:
        product_type = device.get('productType', 'unknown')
        status = device.get('status', 'unknown')
        
        if product_type not in product_stats:
            product_stats[product_type] = {
                'online': 0,
                'offline': 0, 
                'alerting': 0,
                'dormant': 0,
                'total': 0
            }
        
        product_stats[product_type][status] = product_stats[product_type].get(status, 0) + 1
        product_stats[product_type]['total'] += 1
    
    # Display product-based device status

    
    if product_stats:
        # Define the desired display order
        display_order = ['appliance', 'switch', 'wireless', 'camera', 'sensor', 'cellularGateway']
        
        # Filter to only show product types that exist in the data
        available_products = [pt for pt in display_order if pt in product_stats]
        
        # Create columns based on number of available product types (max 4 columns)
        num_products = len(available_products)
        if num_products <= 4:
            cols = st.columns(num_products)
        else:
            # If more than 4 products, use 4 columns and wrap
            cols = st.columns(4)
        
        col_idx = 0
        for product_type in available_products:
            if product_type in product_stats:
                stats = product_stats[product_type]
            with cols[col_idx % len(cols)]:
                # Get product display name
                display_name = product_type_map.get(product_type, f"ğŸ“± {product_type.title()}")
                
                st.markdown(f"### {display_name}")
                
                # Display status counts with colors
                st.markdown(f"""
                <div style="padding: 10px; border-radius: 8px; background: #f8fafc; border: 1px solid #e5e7eb;">
                    <div style="margin-bottom: 8px;">
                        <span style="color: #059669; font-weight: 600; font-size: 1.1rem;">ì˜¨ë¼ì¸: {stats['online']}</span>
                    </div>
                    <div style="margin-bottom: 8px;">
                        <span style="color: #dc2626; font-weight: 600; font-size: 1.1rem;">ì˜¤í”„ë¼ì¸: {stats['offline']}</span>
                    </div>
                    <div style="margin-bottom: 8px;">
                        <span style="color: #d97706; font-weight: 600; font-size: 1.1rem;">ê²½ê³ : {stats['alerting']}</span>
                    </div>
                    <div>
                        <span style="color: #6b7280; font-weight: 600; font-size: 1.1rem;">ë¹„í™œì„±: {stats['dormant']}</span>
                    </div>
                    <hr style="margin: 10px 0; border: 1px solid #e5e7eb;">
                    <div style="text-align: center;">
                        <strong>ì´ {stats['total']}ëŒ€</strong>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
            col_idx += 1
    
    # Calculate overall metrics for alert logic (but don't display)
    online = sum(1 for d in filtered if d["status"] == "online")
    offline = sum(1 for d in filtered if d["status"] == "offline")
    alerting = sum(1 for d in filtered if d["status"] == "alerting")
    dormant = sum(1 for d in filtered if d["status"] == "dormant")
    
     # ì§€ì •ëœ ë©”íŠ¸ë¦­ë“¤ì„ ìˆ¨ê¹€ ì²˜ë¦¬ (ğŸ¥ ë„¤íŠ¸ì›Œí¬ ìƒíƒœ, ğŸš¨ ì¤‘ìš” ì•Œë¦¼, ğŸ“¡ ìƒíƒœ)
    
    # Get devices with issues
    offline_devices = [d for d in filtered if d["status"] == "offline"]
    alerting_devices = [d for d in filtered if d["status"] == "alerting"]
    
    # Real-time Alert Dashboard - only show if there are alerts
    if offline_devices or alerting_devices:
        st.markdown("---")
        st.subheader("ğŸš¨ ì‹¤ì‹œê°„ ì•Œë¦¼ ëŒ€ì‹œë³´ë“œ")
        # Create alert cards
        col1, col2 = st.columns(2)
        
        with col1:
            if offline_devices:
                st.error(f"âŒ **ì˜¤í”„ë¼ì¸ ë””ë°”ì´ìŠ¤: {len(offline_devices)}**")
                for device in offline_devices[:5]:  # Show first 5
                    network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                    st.write(f"â€¢ **{device.get('name', 'Unknown')}** ({network_name}) - {device.get('model', 'N/A')}")
                if len(offline_devices) > 5:
                    st.write(f"... ë° {len(offline_devices) - 5}ê°œ ë”")
        
        with col2:
            if alerting_devices:
                st.warning(f"âš ï¸ **ê²½ê³  ë””ë°”ì´ìŠ¤: {len(alerting_devices)}**")
                for device in alerting_devices[:5]:  # Show first 5
                    network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                    st.write(f"â€¢ **{device.get('name', 'Unknown')}** ({network_name}) - {device.get('model', 'N/A')}")
                if len(alerting_devices) > 5:
                    st.write(f"... ë° {len(alerting_devices) - 5}ê°œ ë”")
        
        # Quick action buttons
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", key="refresh_status"):
                st.session_state.data_load_time = datetime.now()
                st.cache_data.clear()
                st.rerun()
        with col2:
            if st.button("ğŸ“Š ëª¨ë“  ë¬¸ì œ ë³´ê¸°", key="view_issues"):
                st.session_state.show_detailed_alerts = not st.session_state.get('show_detailed_alerts', False)
                st.rerun()
    
    # Show detailed alerts if requested
    if st.session_state.get('show_detailed_alerts', False):
        st.markdown("---")
        st.subheader("ğŸš¨ ìƒì„¸ ì•Œë¦¼ ì •ë³´")
        
        # Get all devices with issues
        offline_devices = [d for d in filtered if d["status"] == "offline"]
        alerting_devices = [d for d in filtered if d["status"] == "alerting"]
        
        if offline_devices or alerting_devices:
            col1, col2 = st.columns(2)
            
            with col1:
                if offline_devices:
                    st.error(f"âŒ **OFFLINE DEVICES: {len(offline_devices)}**")
                    for device in offline_devices:
                        network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                        with st.expander(f"ğŸ”´ {device.get('name', 'Unknown')} ({network_name})", expanded=True):
                            st.write(f"**Device Details:**")
                            st.write(f"- **Name:** {device.get('name', 'Unknown')}")
                            st.write(f"- **Model:** {device.get('model', 'N/A')}")
                            st.write(f"- **Serial:** {device.get('serial', 'N/A')}")
                            st.write(f"- **MAC:** {device.get('mac', 'N/A')}")
                            st.write(f"- **IP:** {device.get('lanIp', 'N/A')}")
                            st.write(f"- **Network:** {network_name}")
                            st.write(f"- **Status:** {device.get('status', 'N/A')}")
                            st.write(f"- **Last Seen:** {device.get('lastReportedAt', 'N/A')}")
                            
                            # Additional device information
                            if device.get('tags'):
                                st.write(f"- **Tags:** {', '.join(device.get('tags', []))}")
                            if device.get('address'):
                                st.write(f"- **Address:** {device.get('address', 'N/A')}")
                            if device.get('notes'):
                                st.write(f"- **Notes:** {device.get('notes', 'N/A')}")
            
            with col2:
                if alerting_devices:
                    st.warning(f"âš ï¸ **ALERTING DEVICES: {len(alerting_devices)}**")
                    for device in alerting_devices:
                        network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                        with st.expander(f"ğŸŸ¡ {device.get('name', 'Unknown')} ({network_name})", expanded=True):
                            st.write(f"**Device Details:**")
                            st.write(f"- **Name:** {device.get('name', 'Unknown')}")
                            st.write(f"- **Model:** {device.get('model', 'N/A')}")
                            st.write(f"- **Serial:** {device.get('serial', 'N/A')}")
                            st.write(f"- **MAC:** {device.get('mac', 'N/A')}")
                            st.write(f"- **IP:** {device.get('lanIp', 'N/A')}")
                            st.write(f"- **Network:** {network_name}")
                            st.write(f"- **Status:** {device.get('status', 'N/A')}")
                            st.write(f"- **Last Seen:** {device.get('lastReportedAt', 'N/A')}")
                            
                            # Additional device information
                            if device.get('tags'):
                                st.write(f"- **Tags:** {', '.join(device.get('tags', []))}")
                            if device.get('address'):
                                st.write(f"- **Address:** {device.get('address', 'N/A')}")
                            if device.get('notes'):
                                st.write(f"- **Notes:** {device.get('notes', 'N/A')}")
                            
                            # Load and display detailed alert information - HIDDEN (ìˆ¨ê¹€ ì²˜ë¦¬)
                            # st.markdown("---")
                            # st.subheader("ğŸš¨ Alert Details")
                            
                            # if device.get('serial'):
                            #     # Load device-specific alerts
                            #     device_alerts = load_device_alerts(api_key, org_id, device.get('serial'))
                            #     
                            #     if device_alerts:
                            #         # Display status events
                            #         if device_alerts.get('status_events'):
                            #             st.write("**ğŸ“Š Status Events:**")
                            #             status_events = device_alerts['status_events']
                            #             # Safely handle the response - check if it's a list
                            #             if isinstance(status_events, list) and len(status_events) > 0:
                            #                 # Show last 5 events
                            #                 for event in status_events[-5:]:
                            #                     event_time = event.get('ts', 'N/A')
                            #                     event_status = event.get('status', 'N/A')
                            #                     st.write(f"- {event_time}: {event_status}")
                            #             else:
                            #                 st.info("Status events data format not as expected")
                            #         
                            #         # Display performance issues
                            #         if device_alerts.get('performance'):
                            #             st.write("**ğŸ“ˆ Performance Issues:**")
                            #             performance_data = device_alerts['performance']
                            #             # Safely handle the response - check if it's a list
                            #             if isinstance(performance_data, list) and len(performance_data) > 0:
                            #                 # Show last 3 performance entries
                            #                 for perf in performance_data[-3:]:
                            #                     loss = perf.get('lossPercent', 'N/A')
                            #                     latency = perf.get('latencyMs', 'N/A')
                            #                     st.write(f"- Loss: {loss}%, Latency: {latency}ms")
                            #             else:
                            #                 st.info("Performance data format not as expected")
                            #         
                            #         # Display security events
                            #         if device_alerts.get('security'):
                            #             st.write("**ğŸ”’ Security Events:**")
                            #             security_data = device_alerts['security']
                            #             # Safely handle the response - check if it's a list
                            #             if isinstance(security_data, list) and len(security_data) > 0:
                            #                 # Show last 3 security events
                            #                 for sec in security_data[-3:]:
                            #                     event_type = sec.get('eventType', 'N/A')
                            #                     event_time = sec.get('occurredAt', 'N/A')
                            #                     st.write(f"- {event_time}: {event_type}")
                            #             else:
                            #                 st.info("Security events data format not as expected")
                            #         
                            #         if not any([device_alerts.get('status_events'), device_alerts.get('performance'), device_alerts.get('security')]):
                            #             st.info("No specific alert details available for this device")
                            #     else:
                            #         st.info("Loading alert details...")
                                
                                # Load network-wide alerts for this device's network - HIDDEN (ìˆ¨ê¹€ ì²˜ë¦¬)
                                # network_alerts = load_network_alerts(api_key, device["networkId"])
                                # if network_alerts:
                                #     st.markdown("---")
                                #     st.subheader("ğŸŒ Network Alerts")
                                #     
                                #     if network_alerts.get('network_events'):
                                #         st.write("**ğŸ“¡ Network Events:**")
                                #         network_events = network_alerts['network_events']
                                #         # Safely handle the response - check if it's a list
                                #         if isinstance(network_events, list) and len(network_events) > 0:
                                #             # Show last 3 network events
                                #             for event in network_events[-3:]:
                                #                 event_type = event.get('type', 'N/A')
                                #                 event_time = event.get('occurredAt', 'N/A')
                                #                 event_desc = event.get('description', 'N/A')
                                #                 st.write(f"- {event_time}: {event_type} - {event_desc}")
                                #         else:
                                #             st.info("Network events data format not as expected")
                                #     
                                #     if network_alerts.get('health_alerts'):
                                #         st.write("**ğŸ¥ Health Alerts:**")
                                #         health_alerts = network_alerts['health_alerts']
                                #         # Safely handle the response - check if it's a list
                                #         if isinstance(health_alerts, list) and len(health_alerts) > 0:
                                #             # Show last 3 health alerts
                                #             for alert in health_alerts[-3:]:
                                #                 alert_type = alert.get('type', 'N/A')
                                #                 alert_time = alert.get('occurredAt', 'N/A')
                                #                 st.write(f"- {alert_time}: {alert_type}")
                                #         else:
                                #             st.info("Health alerts data format not as expected")
                                #     
                                #     if not any([network_alerts.get('network_events'), network_alerts.get('health_alerts')]):
                                #         st.info("No network alerts available")
                                # else:
                                #     st.info("Loading network alerts...")
                            # else:
                            #     st.warning("âš ï¸ Device serial number not available - cannot load detailed alerts")
            
            # Summary and actions
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ë¬¸ì œ", len(offline_devices) + len(alerting_devices))
            with col2:
                st.metric("ì˜¤í”„ë¼ì¸ ë””ë°”ì´ìŠ¤", len(offline_devices))
            with col3:
                st.metric("ê²½ê³  ë””ë°”ì´ìŠ¤", len(alerting_devices))
            
            if st.button("ğŸ”’ ìƒì„¸ ì•Œë¦¼ ìˆ¨ê¸°ê¸°", key="hide_alerts"):
                st.session_state.show_detailed_alerts = False
                st.rerun()
        else:
            st.success("âœ… **ì¤‘ìš”í•œ ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!** ëª¨ë“  ë””ë°”ì´ìŠ¤ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")
            if st.button("ğŸ”’ ìƒì„¸ ì•Œë¦¼ ìˆ¨ê¸°ê¸°", key="hide_alerts"):
                st.session_state.show_detailed_alerts = False
                st.rerun()
    

    # ë„¤íŠ¸ì›Œí¬ë³„ ë””ë°”ì´ìŠ¤ ì„¸ë¶€ì‚¬í•­ë§Œ ìœ ì§€ (col2 ë¶€ë¶„ì„ ë…ë¦½ì ìœ¼ë¡œ í‘œì‹œ)
    if total_d > 0:
        st.subheader("ğŸ” ë””ë°”ì´ìŠ¤ ì„¸ë¶€ì‚¬í•­")
        if filtered:
            # Group devices by network
            network_devices = {}
            for device in filtered:
                network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                if network_name not in network_devices:
                    network_devices[network_name] = {"online": 0, "offline": 0, "alerting": 0, "dormant": 0}
                
                status = device.get("status", "unknown")
                if status == "online":
                    network_devices[network_name]["online"] += 1
                elif status == "offline":
                    network_devices[network_name]["offline"] += 1
                elif status == "alerting":
                    network_devices[network_name]["alerting"] += 1
                elif status == "dormant":
                    network_devices[network_name]["dormant"] += 1
            
            # Display network breakdown
            for network_idx, (network, counts) in enumerate(network_devices.items()):
                with st.expander(f"ğŸŒ {network} ({sum(counts.values())} devices)", expanded=True):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("âœ… ì˜¨ë¼ì¸", counts["online"])
                        with col2:
                            st.metric("âŒ ì˜¤í”„ë¼ì¸", counts["offline"])
                        with col3:
                            st.metric("âš ï¸ ê²½ê³ ", counts["alerting"])
                        with col4:
                            st.metric("ğŸ˜´ ë¹„í™œì„±", counts["dormant"])
                        
                        # Show detailed device list for this network
                        network_device_list = [d for d in filtered if next((name for name, net_id in net_map.items() if net_id == d["networkId"]), "") == network]
                        if network_device_list:
                            st.markdown("**ğŸ“‹ ë””ë°”ì´ìŠ¤ ì„¸ë¶€ì‚¬í•­:**")
                            
                            # ULTRA-FAST device details - skip slow system info loading
                            device_details = []
                            for device in network_device_list:
                                # Skip slow system info loading for speed
                                # Use basic device info only
                                os_version = "N/A"  # Skip loading for speed
                                power_status = "N/A"  # Skip loading for speed
                                cpu_usage = "N/A"  # Skip loading for speed
                                
                                # Format status with colors for display
                                status = device.get("status", "Unknown")
                                if status == "online":
                                    status_display = "ğŸŸ¢ ì˜¨ë¼ì¸"
                                elif status == "offline":
                                    status_display = "ğŸ”´ ì˜¤í”„ë¼ì¸"
                                elif status == "alerting":
                                    status_display = "ğŸŸ¡ ê²½ê³ "
                                else:
                                    status_display = f"âšª {status}"
                                
                                # Format power status with colors
                                if power_status == "on":
                                    power_display = "ğŸŸ¢ On"
                                elif power_status == "off":
                                    power_display = "ğŸ”´ Off"
                                else:
                                    power_display = power_status
                                
                                device_details.append({
                                    "ë²ˆí˜¸": len(device_details) + 1,
                                    "ë””ë°”ì´ìŠ¤ëª…": device.get("name", "Unknown"),
                                    "ëª¨ë¸": device.get("model", "N/A"),
                                    "ì‹œë¦¬ì–¼": device.get("serial", "N/A"),
                                    "ìƒíƒœ": status_display,
                                    "MAC": device.get("mac", "N/A"),
                                    "IP": device.get("lanIp", "N/A"),
                                    "OS ë²„ì „": os_version,
                                    "ì „ì› ìƒíƒœ": power_display,
                                    "CPU ì‚¬ìš©ë¥ ": cpu_usage
                                })
                            
                            # Create DataFrame and display
                            device_df = pd.DataFrame(device_details)
                            
                            # Display the enhanced table
                            st.dataframe(device_df, use_container_width=True, hide_index=True)
                            
                            # Add event log download with selectbox for better handling of many devices
                            st.markdown("**ğŸ“„ ì´ë²¤íŠ¸ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ:**")
                            
                            # Create device options for selectbox
                            device_options = []
                            for i, device in enumerate(network_device_list):
                                device_name = device.get("name", "Unknown")
                                device_serial = device.get("serial", "N/A")
                                device_options.append((f"{i+1}. {device_name} ({device_serial})", i))
                            
                            # Get network_id safely
                            network_id = ""
                            if network_device_list:
                                network_id = network_device_list[0].get("networkId", "")
                            
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                selected_device_idx = st.selectbox(
                                    "ë””ë°”ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                                    options=[idx for _, idx in device_options],
                                    format_func=lambda x: device_options[x][0],
                                    key=f"event_log_select_{network_idx}_{network_id}_{len(network_device_list)}",
                                    help="ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ë‹¤ìš´ë¡œë“œí•  ë””ë°”ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                                )
                            
                            with col2:
                                st.markdown("&nbsp;")  # ë¹ˆ ê³µê°„ (selectbox ë¼ë²¨ê³¼ ê°™ì€ ë†’ì´)

                                selected_device = network_device_list[selected_device_idx]
                                device_name = selected_device.get("name", "Unknown")
                                device_serial = selected_device.get("serial", "N/A")
                                # network_id is already defined above
                                product_type = selected_device.get("productType", "")
                                
                                st.markdown(
                                    """
                                    <style>
                                    /* ì´ ë²„íŠ¼ì—ë§Œ margin-top ì ìš© */
                                    .generate-log-btn {
                                        margin-bottom: 0.5rem;
                                    }
                                    </style>
                                    """, unsafe_allow_html=True
                                )

                                if st.button("ğŸ“„ ë¡œê·¸ ìƒì„±", key=f"generate_log_{network_idx}_{device_serial}_{network_id}", 
                                           help=f"{device_name}ì˜ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±", 
                                           use_container_width=True):
                                    print(f"\nğŸ”´ ì‚¬ìš©ìê°€ ë¡œê·¸ ìƒì„± ë²„íŠ¼ í´ë¦­!")
                                    print(f"   ğŸ‘¤ Device: {device_name}")
                                    print(f"   ğŸ”¢ Serial: {device_serial}")
                                    print(f"   ğŸŒ Network: {network_id}")
                                    print(f"   ğŸ“± Product Type: {product_type}")
                                    
                                    with st.spinner(f"{device_name} ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì¤‘..."):
                                        print(f"   ğŸ“¡ API í˜¸ì¶œ ì‹œì‘...")
                                        events = load_device_events(api_key, network_id, device_serial, product_type)
                                        print(f"   ğŸ“ ë¡œê·¸ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
                                        log_content = generate_event_log_text(events, device_serial)
                                        print(f"   âœ… ë¡œê·¸ ìƒì„± ì™„ë£Œ: {len(log_content)} ë¬¸ì")
                                        
                                        # Store in session state for download
                                        st.session_state[f'log_content_{device_serial}'] = log_content
                                        st.session_state[f'log_filename_{device_serial}'] = f"{device_name}_{device_serial}_events_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                                        print(f"   ğŸ’¾ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ ì™„ë£Œ")
                                        st.rerun()
                            
                            # Show download button if log content is ready
                            if f'log_content_{device_serial}' in st.session_state:
                                st.download_button(
                                    label=f"ğŸ“¥ {device_name}_events.txt ë‹¤ìš´ë¡œë“œ",
                                    data=st.session_state[f'log_content_{device_serial}'],
                                    file_name=st.session_state[f'log_filename_{device_serial}'],
                                    mime="text/plain",
                                    key=f"download_btn_{network_idx}_{device_serial}_{network_id}",
                                    use_container_width=True
                                )
                                # Clear the session state after showing download button
                                del st.session_state[f'log_content_{device_serial}']
                                del st.session_state[f'log_filename_{device_serial}']
        else:
            st.warning("âš ï¸ ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ë„¤íŠ¸ì›Œí¬ í•„í„°ë§ ê³¼ì •ì—ì„œ ë””ë°”ì´ìŠ¤ê°€ ìˆëŠ” ë„¤íŠ¸ì›Œí¬ë§Œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ ë„¤íŠ¸ì›Œí¬ í•„í„°ë§ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    # Add comprehensive device status table - MOVED OUTSIDE OF NETWORK LOOP
    if total_d > 0:
        st.markdown("---")
        st.subheader("ğŸ“Š ì¢…í•© ë””ë°”ì´ìŠ¤ ìƒíƒœ í…Œì´ë¸”")
        
        if filtered:
            # Create comprehensive device table
            comprehensive_devices = []
            for device in filtered:
                network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                comprehensive_devices.append({
                    "ë„¤íŠ¸ì›Œí¬": network_name,
                    "ë””ë°”ì´ìŠ¤ëª…": device.get("name", "Unknown"),
                    "ëª¨ë¸": device.get("model", "N/A"),
                    "ìƒíƒœ": device.get("status", "Unknown"),
                    "ì‹œë¦¬ì–¼": device.get("serial", "N/A"),
                    "MAC": device.get("mac", "N/A"),
                    "IP": device.get("lanIp", "N/A"),
                    "íŒì›¨ì–´": device.get("firmware", "N/A"),
                    "ë§ˆì§€ë§‰ í™•ì¸": device.get("lastReportedAt", "N/A")
                })
            
            comprehensive_df = pd.DataFrame(comprehensive_devices)
            
            # Add status-based filtering
            col1, col2 = st.columns(2)
            with col1:
                status_filter = st.selectbox("ìƒíƒœë³„ í•„í„°", ["ì „ì²´", "online", "offline", "alerting", "dormant"], key="comprehensive_status_filter")
            with col2:
                network_filter = st.selectbox("ë„¤íŠ¸ì›Œí¬ë³„ í•„í„°", ["ì „ì²´"] + list(net_map.keys()), key="comprehensive_network_filter")
            
            # Apply filters
            filtered_df = comprehensive_df.copy()
            if status_filter != "ì „ì²´":
                filtered_df = filtered_df[filtered_df["ìƒíƒœ"] == status_filter]
            if network_filter != "ì „ì²´":
                filtered_df = filtered_df[filtered_df["ë„¤íŠ¸ì›Œí¬"] == network_filter]
            
            st.dataframe(filtered_df, use_container_width=True, hide_index=True)
            
            # Summary statistics
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric("ì´ ë””ë°”ì´ìŠ¤", len(filtered_df))
            with col2:
                st.metric("ì˜¨ë¼ì¸", len(filtered_df[filtered_df["ìƒíƒœ"] == "online"]))
            with col3:
                st.metric("ì˜¤í”„ë¼ì¸", len(filtered_df[filtered_df["ìƒíƒœ"] == "offline"]))
            with col4:
                st.metric("ê²½ê³ ", len(filtered_df[filtered_df["ìƒíƒœ"] == "alerting"]))
            with col5:
                st.metric("ë¹„í™œì„±", len(filtered_df[filtered_df["ìƒíƒœ"] == "dormant"]))
        else:
            st.info("ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    else:
        st.warning("ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

elif current_page == "íŠ¸ë˜í”½ ë¶„ì„":
    st.header("ğŸŒ íŠ¸ë˜í”½ ë¶„ì„ (ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íŒ¨í„´ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš©ëŸ‰)")
    
    if not enable_traffic:
        st.info("ğŸ”§ ì‚¬ì´ë“œë°”ì—ì„œ íŠ¸ë˜í”½ ë¶„ì„ì„ í™œì„±í™”í•˜ì—¬ íŠ¸ë˜í”½ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    else:
        # Load traffic data only when user visits this page (on-demand loading)
        print("=" * 60)
        print("ON-DEMAND TRAFFIC ANALYSIS DATA LOADING")
        print("=" * 60)
        
        with st.spinner("íŠ¸ë˜í”½ ë°ì´í„° ë¡œë”© ì¤‘..."):
            traffic_data = load_traffic_analysis_data_parallel(api_key, sel_nets, timespan, resolution)
        
        print(f"âœ… Traffic analysis data loaded in {traffic_data['load_time']:.2f} seconds")
        print("=" * 60)
        
        for net_id in sel_nets:
            # Find the display name for this network ID
            display_name = next((name for name, nid in net_map.items() if nid == net_id), f"Network_{net_id}")
            
            # Extract data from parallel results
            network_data = traffic_data['network_data'].get(net_id, {})
            comprehensive_traffic = network_data.get('traffic', {})
            bandwidth_data = network_data.get('bandwidth', [])
            clients_data = network_data.get('clients', [])
            
            # Check if we have any traffic data
            has_traffic_data = any(data for data in comprehensive_traffic.values()) if comprehensive_traffic else False
            
            if not has_traffic_data and not bandwidth_data:
                # Skip networks with no data instead of showing warning
                continue
            
            # Get time range information for display
            timespan_hours = timespan / 3600 if timespan else 1
            time_range_text = f"{timespan_hours:.1f}ì‹œê°„" if timespan_hours < 24 else f"{timespan_hours/24:.1f}ì¼"
            
            # Create a visually distinct card for each network
            st.markdown("""
            <div style="
                height: 3px;
                background: linear-gradient(90deg, #667eea, #764ba2, #667eea);
                margin: 2rem 0;
                border-radius: 2px;
            "></div>
            """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                padding: 1.5rem;
                border-radius: 15px;
                margin: 1rem 0;
                box-shadow: 0 8px 32px rgba(0,0,0,0.1);
                border: 1px solid rgba(255,255,255,0.2);
            ">
                <h2 style="
                    color: white;
                    margin: 0 0 0.5rem 0;
                    font-size: 1.8rem;
                    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
                ">ğŸŒ {display_name}</h2>
                <p style="
                    color: rgba(255,255,255,0.9);
                    margin: 0;
                    font-size: 1.1rem;
                ">ì¢…í•© íŠ¸ë˜í”½ ë¶„ì„ (ëª¨ë“  ë””ë°”ì´ìŠ¤ íƒ€ì…) â€¢ {time_range_text} ê¸°ì¤€</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Create content container for better organization
            with st.container():
                
                # Display device type breakdown
                if comprehensive_traffic:
                    st.markdown("### ğŸ“Š ë””ë°”ì´ìŠ¤ íƒ€ì…ë³„ ë°ì´í„° í˜„í™©")
                col1, col2, col3, col4 = st.columns(4)
                
                device_type_names = {
                    'combined': 'ğŸ”„ í†µí•©',
                    'wireless': 'ğŸ“¶ ë¬´ì„ ',
                    'switch': 'ğŸ”Œ ìŠ¤ìœ„ì¹˜', 
                    'appliance': 'ğŸ›¡ï¸ ì–´í”Œë¼ì´ì–¸ìŠ¤'
                }
                
                for i, (device_type, data) in enumerate(comprehensive_traffic.items()):
                    with [col1, col2, col3, col4][i]:
                        app_count = len(data) if data else 0
                        st.metric(
                            device_type_names.get(device_type, device_type.upper()),
                            f"{app_count}",
                            help=f"{device_type} ë””ë°”ì´ìŠ¤ íƒ€ì…ì—ì„œ ê°ì§€ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜"
                        )
            
            # Combine all traffic data from all device types
            all_apps = combine_traffic_data(comprehensive_traffic)
            top_apps = pd.DataFrame()
            
            # Initialize traffic metrics
            total_traffic_mb = 0
            total_traffic_gb = 0
            total_downstream_bytes = 0
            total_upstream_bytes = 0
            total_bytes = 0
            
            if not all_apps.empty:
                # Convert to MB for display
                all_apps["sent_MB"] = all_apps["sent"] / (1024 * 1024)
                all_apps["recv_MB"] = all_apps["recv"] / (1024 * 1024)
                all_apps["TotalMB"] = all_apps["sent_MB"] + all_apps["recv_MB"]
                
                # Sort by TotalMB descending and get top 15 for display only
                top_apps = all_apps.nlargest(15, "TotalMB").reset_index(drop=True)
                
                # Calculate total traffic from combined data
                total_sent_bytes = all_apps["sent"].sum()
                total_recv_bytes = all_apps["recv"].sum()
                total_bytes = total_sent_bytes + total_recv_bytes
                total_traffic_mb = total_bytes / (1024 * 1024)
                total_traffic_gb = total_traffic_mb / 1024
                total_downstream_bytes = total_recv_bytes
                total_upstream_bytes = total_sent_bytes
            else:
                # Show detailed information when no data is available
                st.warning(f"âš ï¸ {display_name}ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                # Fallback to bandwidth data if no traffic data
                if bandwidth_data:
                    df = pd.DataFrame(bandwidth_data)
                    if len(df) > 0 and 'downstream' in df.columns and 'upstream' in df.columns:
                        # Convert Mbps to bytes (assuming Mbps values)
                        df["downstream_bytes"] = df["downstream"] * 1024 * 1024 / 8
                        df["upstream_bytes"] = df["upstream"] * 1024 * 1024 / 8
                        df["total_bytes"] = df["downstream_bytes"] + df["upstream_bytes"]
                        
                        total_downstream_bytes = df["downstream_bytes"].sum()
                        total_upstream_bytes = df["upstream_bytes"].sum()
                        total_bytes = total_downstream_bytes + total_upstream_bytes
                        total_traffic_mb = total_bytes / (1024 * 1024)
                        total_traffic_gb = total_traffic_mb / 1024
                else:
                    st.error("âŒ ëŒ€ì²´ ë°ì´í„° ì†ŒìŠ¤ë„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # Enhanced metrics display with time range information
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ğŸ“Š ì´ íŠ¸ë˜í”½", f"{total_traffic_mb:.2f} MB", 
                             help=f"ì§€ë‚œ {time_range_text} ë™ì•ˆì˜ ì´ íŠ¸ë˜í”½ ë³¼ë¥¨ (ì—…ë¡œë“œ + ë‹¤ìš´ë¡œë“œ)")
                    st.metric("ğŸ“Š ì´ íŠ¸ë˜í”½ (GB)", f"{total_traffic_gb:.3f} GB", 
                             help=f"ì§€ë‚œ {time_range_text} ë™ì•ˆì˜ ì´ íŠ¸ë˜í”½ ë³¼ë¥¨ (GB ë‹¨ìœ„)")
            
            with col2:
                upload_mb = total_upstream_bytes / (1024 * 1024)
                download_mb = total_downstream_bytes / (1024 * 1024)
                st.metric("ğŸ“¤ ì´ ì—…ë¡œë“œ", f"{upload_mb:.2f} MB", 
                             help=f"ì§€ë‚œ {time_range_text} ë™ì•ˆì˜ ì´ ì—…ë¡œë“œ íŠ¸ë˜í”½")
                st.metric("ğŸ“¥ ì´ ë‹¤ìš´ë¡œë“œ", f"{download_mb:.2f} MB", 
                             help=f"ì§€ë‚œ {time_range_text} ë™ì•ˆì˜ ì´ ë‹¤ìš´ë¡œë“œ íŠ¸ë˜í”½")
            
            with col3:
                # Get accurate client count using multiple methods
                total_client_count = 0
                client_count_source = "N/A"
                
                # Method 1: Try to get from clients overview API (most accurate)
                try:
                    clients_overview = load_network_clients_overview(api_key, net_id)
                    if clients_overview and 'counts' in clients_overview:
                        counts = clients_overview['counts']
                        total_client_count = counts.get('total', 0)
                        client_count_source = "Overview API"
                    elif clients_overview and 'total' in clients_overview:
                        total_client_count = clients_overview['total']
                        client_count_source = "Overview API"
                except:
                    pass
                
                # Method 2: Fallback to actual connected clients count
                if total_client_count == 0 and clients_data:
                    total_client_count = len(clients_data)
                    client_count_source = "Connected Clients"
                
                # Method 3: Fallback to application data
                if total_client_count == 0 and len(all_apps) > 0:
                    total_client_count = all_apps["numClients"].max()  # Use max instead of sum
                    client_count_source = "Application Data (Max)"
                
                st.metric("ğŸ‘¥ ì´ í´ë¼ì´ì–¸íŠ¸", f"{total_client_count}", 
                         help=f"í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ({client_count_source}) - ìµœëŒ€ 5000ê°œê¹Œì§€ ë¡œë“œ")
            
            with col4:
                # Get total application count (no limit)
                total_applications = len(all_apps) if len(all_apps) > 0 else 0
                st.metric("ğŸ“± ì´ ì• í”Œë¦¬ì¼€ì´ì…˜", f"{total_applications}", 
                         help=f"ì§€ë‚œ {time_range_text} ë™ì•ˆ ê°ì§€ëœ ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜")
                
            # Enhanced traffic breakdown with time range context
            st.markdown("---")
            st.subheader(f"ğŸ“Š íŠ¸ë˜í”½ ìƒì„¸ ë¶„ì„ ({time_range_text} ê¸°ì¤€)")
            
            # Time range context box
            st.info(f"â° **ë¶„ì„ ê¸°ê°„**: ì§€ë‚œ {time_range_text} | **ë°ì´í„° í¬ì¸íŠ¸**: {len(all_apps) if not all_apps.empty else 0}ê°œ | **ë„¤íŠ¸ì›Œí¬**: {display_name}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ğŸ“ˆ íŠ¸ë˜í”½ ë¶„í¬:**")
                upload_percentage = (total_upstream_bytes / total_bytes * 100) if total_bytes > 0 else 0
                download_percentage = (total_downstream_bytes / total_bytes * 100) if total_bytes > 0 else 0
                upload_mb = total_upstream_bytes / (1024 * 1024)
                download_mb = total_downstream_bytes / (1024 * 1024)
                st.write(f"â€¢ ì—…ë¡œë“œ: {upload_mb:.2f} MB ({upload_percentage:.1f}%)")
                st.write(f"â€¢ ë‹¤ìš´ë¡œë“œ: {download_mb:.2f} MB ({download_percentage:.1f}%)")
                st.write(f"â€¢ ì´ íŠ¸ë˜í”½: {total_traffic_mb:.2f} MB")
                st.write(f"â€¢ ì‹œê°„ë‹¹ í‰ê· : {total_traffic_mb / timespan_hours:.2f} MB/h")
                
            with col2:
                st.markdown("**ğŸ“Š ë°ì´í„° í’ˆì§ˆ:**")
                st.write(f"â€¢ ë°ì´í„° í¬ì¸íŠ¸: {len(all_apps) if not all_apps.empty else 0}ê°œ")
                st.write(f"â€¢ ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜: {total_applications}ê°œ")
                st.write(f"â€¢ í‰ê·  ì•±ë‹¹ íŠ¸ë˜í”½: {total_traffic_mb / total_applications:.2f} MB" if total_applications > 0 else "â€¢ í‰ê·  ì•±ë‹¹ íŠ¸ë˜í”½: N/A")
                st.write(f"â€¢ í´ë¼ì´ì–¸íŠ¸ë‹¹ í‰ê· : {total_traffic_mb / total_client_count:.2f} MB" if total_client_count > 0 else "â€¢ í´ë¼ì´ì–¸íŠ¸ë‹¹ í‰ê· : N/A")
            
            st.markdown("---")
            
            # Enhanced traffic visualization with time range
            st.subheader(f"ğŸ“Š ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½ ê°œìš” ({time_range_text} ê¸°ì¤€)")
            
            # Show comprehensive application statistics
            if len(all_apps) > 0:
                st.info(f"ğŸ“Š **ì „ì²´ í†µê³„**: {len(all_apps)}ê°œ ì• í”Œë¦¬ì¼€ì´ì…˜, ì´ {total_client_count}ëª… í´ë¼ì´ì–¸íŠ¸")
                
                # Show top applications chart
                if len(top_apps) > 0:
                    try:
                        # Validate data before creating chart
                        if not top_apps.empty and 'TotalMB' in top_apps.columns and 'application' in top_apps.columns:
                            # Create enhanced horizontal bar chart with better formatting
                            fig = px.bar(
                                top_apps,
                                x="TotalMB",
                                y="application",
                                orientation="h",
                                height=max(400, len(top_apps) * 30),  # Dynamic height based on number of apps
                                title=f"ìƒìœ„ {len(top_apps)}ê°œ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½ - {display_name} ({time_range_text})",
                                color="TotalMB",
                                color_continuous_scale="viridis",
                                text="TotalMB"
                            )
                            
                            # Format text labels
                            fig.update_traces(
                                texttemplate='%{text:.1f}MB',
                                textposition='outside',
                                hovertemplate='<b>%{y}</b><br>íŠ¸ë˜í”½: %{x:.2f}MB<br>í´ë¼ì´ì–¸íŠ¸: %{customdata[0]}<extra></extra>',
                                customdata=top_apps[['numClients']].values
                            )
                            
                            fig.update_layout(
                                xaxis_title="íŠ¸ë˜í”½ ë³¼ë¥¨ (MB)",
                                yaxis_title="ì• í”Œë¦¬ì¼€ì´ì…˜",
                                showlegend=False,
                                plot_bgcolor='rgba(0,0,0,0)',
                                paper_bgcolor='rgba(0,0,0,0)',
                                margin=dict(l=200)  # More space for app names
                            )
                            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128,128,128,0.2)')
                            fig.update_yaxes(showgrid=False)
                            st.plotly_chart(fig, use_container_width=True, key=f"traffic_chart_{net_id}")
                        else:
                            st.warning("ì°¨íŠ¸ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    except Exception as chart_error:
                        # Hide chart section when error occurs
                        pass
                
                # Additional traffic insights with time context
                st.markdown("---")
                st.subheader(f"ğŸ“ˆ íŠ¸ë˜í”½ ì¸ì‚¬ì´íŠ¸ ({time_range_text} ê¸°ì¤€)")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ğŸ”¥ ìƒìœ„ 5ê°œ ì• í”Œë¦¬ì¼€ì´ì…˜:**")
                    for i, (_, app) in enumerate(top_apps.head(5).iterrows(), 1):
                        percentage = (app['TotalMB'] / total_traffic_mb) * 100 if total_traffic_mb > 0 else 0
                        st.write(f"{i}. **{app['application']}**: {app['TotalMB']:.1f}MB ({percentage:.1f}%)")
                
                with col2:
                    st.markdown("**ğŸ“Š ì „ì²´ íŠ¸ë˜í”½ í†µê³„:**")
                    if len(all_apps) > 0:
                        st.write(f"â€¢ ì´ ì• í”Œë¦¬ì¼€ì´ì…˜: {len(all_apps)}ê°œ")
                        st.write(f"â€¢ ìµœëŒ€ ì•± íŠ¸ë˜í”½: {all_apps['TotalMB'].max():.1f}MB")
                        st.write(f"â€¢ í‰ê·  ì•± íŠ¸ë˜í”½: {all_apps['TotalMB'].mean():.1f}MB")
                        st.write(f"â€¢ ì¤‘ê°„ê°’ ì•± íŠ¸ë˜í”½: {all_apps['TotalMB'].median():.1f}MB")
                        st.write(f"â€¢ ìƒìœ„ 5ê°œ ì•± ë¹„ìœ¨: {(top_apps.head(5)['TotalMB'].sum() / total_traffic_mb * 100):.1f}%" if total_traffic_mb > 0 else "â€¢ ìƒìœ„ 5ê°œ ì•± ë¹„ìœ¨: 0%")
                        st.write(f"â€¢ ì‹œê°„ë‹¹ í‰ê· : {total_traffic_mb / timespan_hours:.2f} MB/h")
                
                # Show ALL applications table
                st.markdown("---")
                st.subheader(f"ğŸ“‹ ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜ ëª©ë¡ ({len(all_apps)}ê°œ)")
                
                if len(all_apps) > 0:
                    # Create comprehensive display table
                    display_apps = all_apps.copy()
                    display_apps['Percentage'] = (display_apps['TotalMB'] / total_traffic_mb * 100).round(2) if total_traffic_mb > 0 else 0
                    display_apps = display_apps.sort_values('TotalMB', ascending=False)
                    
                    # Format the display
                    display_apps['TotalMB'] = display_apps['TotalMB'].round(2)
                    display_apps['numClients'] = display_apps['numClients'].astype(int)
                    
                    st.dataframe(
                        display_apps[['application', 'TotalMB', 'numClients', 'deviceType', 'Percentage']].rename(columns={
                            'application': 'ì• í”Œë¦¬ì¼€ì´ì…˜',
                            'TotalMB': 'íŠ¸ë˜í”½ (MB)',
                            'numClients': 'í´ë¼ì´ì–¸íŠ¸ ìˆ˜',
                            'deviceType': 'ë””ë°”ì´ìŠ¤ íƒ€ì…',
                            'Percentage': 'ë¹„ìœ¨ (%)'
                        }),
                        use_container_width=True,
                        hide_index=True
                    )
                
                # Close the content container for this network
                st.markdown("</div>", unsafe_allow_html=True)
                
                # Add separator line after each network
                st.markdown("""
                <div style="
                    height: 2px;
                    background: linear-gradient(90deg, transparent, #667eea, transparent);
                    margin: 2rem 0;
                "></div>
                """, unsafe_allow_html=True)
                
                # Enhanced debug information with time context
                if SHOW_DEBUG_INFO:
                    with st.expander(f"ğŸ” Debug: Traffic Calculation & API Data ({time_range_text} ê¸°ì¤€)", expanded=True):
                        st.write(f"**ğŸ“Š íŠ¸ë˜í”½ ê³„ì‚° ìƒì„¸:**")
                        st.write(f"- ë¶„ì„ ê¸°ê°„: {time_range_text} ({timespan}ì´ˆ)")
                        st.write(f"- ì‚¬ìš©ëœ API: Network Traffic + Network Bandwidth")
                        st.write(f"- Traffic ë°ì´í„° í¬ì¸íŠ¸: {len(traffic_data) if traffic_data else 0}ê°œ")
                        st.write(f"- Bandwidth ë°ì´í„° í¬ì¸íŠ¸: {len(bandwidth_data) if bandwidth_data else 0}ê°œ")
                        st.write(f"- í´ë¼ì´ì–¸íŠ¸ ë°ì´í„°: {len(clients_data) if clients_data else 0}ê°œ")
                        st.write(f"- ì´ ì—…ë¡œë“œ ë°”ì´íŠ¸: {total_upstream_bytes:,} bytes")
                        st.write(f"- ì´ ë‹¤ìš´ë¡œë“œ ë°”ì´íŠ¸: {total_downstream_bytes:,} bytes")
                        st.write(f"- ì´ ë°”ì´íŠ¸: {total_bytes:,} bytes")
                        st.write(f"- ì´ íŠ¸ë˜í”½ (MB): {total_traffic_mb:.2f} MB")
                        st.write(f"- ì´ íŠ¸ë˜í”½ (GB): {total_traffic_gb:.3f} GB")
                        st.write(f"- ì‹œê°„ë‹¹ í‰ê· : {total_traffic_mb / timespan_hours:.2f} MB/h")
                        st.write(f"- ì´ í´ë¼ì´ì–¸íŠ¸: {total_client_count}")
                        st.write(f"- ì´ ì• í”Œë¦¬ì¼€ì´ì…˜: {total_applications}")
                        st.write(f"- í‘œì‹œëœ ì• í”Œë¦¬ì¼€ì´ì…˜: {len(top_apps)}ê°œ (ìƒìœ„ 15ê°œ)")
                        
                        st.write("**ğŸ“ˆ ì „ì²´ ë°ì´í„° í’ˆì§ˆ ê²€ì¦:**")
                        if len(all_apps) > 0:
                            st.write(f"- í‰ê·  ì•±ë‹¹ íŠ¸ë˜í”½: {total_traffic_mb / len(all_apps):.2f} MB")
                            st.write(f"- ìµœëŒ€ ì•± íŠ¸ë˜í”½: {all_apps['TotalMB'].max():.2f} MB")
                            st.write(f"- ìµœì†Œ ì•± íŠ¸ë˜í”½: {all_apps['TotalMB'].min():.2f} MB")
                            st.write(f"- ì´ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ (ëª¨ë“  ì•±): {all_apps['numClients'].sum()}")
                        st.write(f"- ì—…ë¡œë“œ ë¹„ìœ¨: {upload_percentage:.1f}%")
                        st.write(f"- ë‹¤ìš´ë¡œë“œ ë¹„ìœ¨: {download_percentage:.1f}%")
                        
                        st.write("**ğŸ” ë””ë°”ì´ìŠ¤ íƒ€ì…ë³„ API ë°ì´í„°:**")
                        if comprehensive_traffic:
                            for device_type, data in comprehensive_traffic.items():
                                if data:
                                    st.write(f"**{device_type.upper()} ({len(data)}):**")
                                    st.json(data[0] if len(data) > 0 else {})
                                    st.write("---")
                        
                        st.write("**ğŸ” í†µí•©ëœ ë°ì´í„° ìƒ˜í”Œ:**")
                        if not all_apps.empty:
                            st.json(all_apps.iloc[0].to_dict())
                        
                        st.write("**ğŸ“‹ ì²˜ë¦¬ëœ DataFrame ìƒ˜í”Œ:**")
                        st.dataframe(df.head())
                        
                        st.write("**ğŸ“Š ìƒìœ„ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„¸:**")
                        st.dataframe(top_apps.head(10))
            else:
                st.info("No application data available")
            
            # Detailed traffic table with intuitive format
            st.markdown("---")
            st.subheader("ğŸ” Application Traffic Details")
            
            if len(top_apps) > 0:
                # Create intuitive display format
                display_data = []
                for _, app in top_apps.iterrows():
                    app_name = app["application"]
                    total_mb = app["TotalMB"]
                    clients = app["numClients"]
                    
                    # Format: Application Name (TotalMB MB)
                    display_name = f"{app_name} ({total_mb:.1f}MB)"
                    display_data.append({
                        "Application": display_name,
                        "Traffic (MB)": f"{total_mb:.1f}",
                        "Clients": clients,
                        "Upload (MB)": f"{app['sent']/1024/1024:.1f}",
                        "Download (MB)": f"{app['recv']/1024/1024:.1f}"
                    })
                
                display_df = pd.DataFrame(display_data)
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True
                )
                
                # Show raw data for debugging
                if SHOW_DEBUG_INFO:
                    with st.expander("ğŸ” Debug: Raw Application Data", expanded=True):
                        st.write("**Top Applications DataFrame:**")
                        st.dataframe(top_apps)
                        
                        st.write("**Data Processing Steps:**")
                        st.write("1. Group by application name")
                        st.write("2. Sum TotalMB (sent + received)")
                        st.write("3. Take max numClients per application")
                        st.write("4. Sort by TotalMB descending")
            else:
                st.info("No detailed traffic data available")
                
                # Close the content container for this network
                st.markdown("</div>", unsafe_allow_html=True)
        
        # Add comprehensive traffic analysis table across all networks
        st.markdown("---")
        st.subheader("ğŸŒ Cross-Network Traffic Analysis")
        
        # Collect traffic data from all networks
        all_network_traffic = []
        for net_id in sel_nets:
            # Find the display name for this network ID
            display_name = next((name for name, nid in net_map.items() if nid == net_id), f"Network_{net_id}")
            data = load_traffic(api_key, net_id, timespan)
            if data:
                df = pd.DataFrame(data)
                df["TotalMB"] = (df["sent"] + df["recv"]) / 1024 / 1024
                df["Network"] = display_name
                
                # Aggregate by application across network
                network_apps = df.groupby("application").agg({
                    "TotalMB": "sum",
                    "numClients": "max",
                    "sent": "sum",
                    "recv": "sum"
                }).reset_index()
                network_apps["Network"] = display_name
                all_network_traffic.append(network_apps)
        
        if all_network_traffic:
            # Combine all network data
            combined_traffic = pd.concat(all_network_traffic, ignore_index=True)
            
            # Create comprehensive analysis
            comprehensive_traffic = combined_traffic.groupby("application").agg({
                "TotalMB": "sum",
                "numClients": "max",
                "sent": "sum",
                "recv": "sum",
                "Network": lambda x: ", ".join(x.unique())
            }).reset_index()
            
            # Sort by total traffic
            comprehensive_traffic = comprehensive_traffic.sort_values("TotalMB", ascending=False)
            
            # Display comprehensive table
            st.markdown("**ğŸ“Š All Networks - Application Traffic Summary**")
            
            # Add filtering options
            col1, col2 = st.columns(2)
            with col1:
                min_traffic = st.number_input("Minimum Traffic (MB)", min_value=0.0, value=1.0, step=0.1, key="traffic_min_filter")
            with col2:
                app_search = st.text_input("Search Applications", placeholder="Enter application name", key="traffic_app_search")
            
            # Apply filters
            filtered_traffic = comprehensive_traffic[comprehensive_traffic["TotalMB"] >= min_traffic]
            if app_search:
                filtered_traffic = filtered_traffic[filtered_traffic["application"].str.contains(app_search, case=False, na=False)]
            
            # Display filtered results
            if len(filtered_traffic) > 0:
                display_comprehensive = []
                for _, app in filtered_traffic.iterrows():
                    display_comprehensive.append({
                        "ì• í”Œë¦¬ì¼€ì´ì…˜": app["application"],
                        "ì´ íŠ¸ë˜í”½ (MB)": f"{app['TotalMB']:.2f}",
                        "ì´ íŠ¸ë˜í”½ (GB)": f"{app['TotalMB']/1024:.3f}",
                        "ìµœëŒ€ í´ë¼ì´ì–¸íŠ¸": app["numClients"],
                        "ì—…ë¡œë“œ (MB)": f"{app['sent']/1024/1024:.2f}",
                        "ë‹¤ìš´ë¡œë“œ (MB)": f"{app['recv']/1024/1024:.2f}",
                        "ë„¤íŠ¸ì›Œí¬": app["Network"]
                    })
                
                comprehensive_df = pd.DataFrame(display_comprehensive)
                st.dataframe(comprehensive_df, use_container_width=True, hide_index=True)
                
                # Summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ì• í”Œë¦¬ì¼€ì´ì…˜", len(filtered_traffic))
                with col2:
                    st.metric("ì´ íŠ¸ë˜í”½", f"{filtered_traffic['TotalMB'].sum():.2f} MB")
                with col3:
                    st.metric("ì´ ì—…ë¡œë“œ", f"{filtered_traffic['sent'].sum()/1024/1024:.2f} MB")
                with col4:
                    st.metric("ì´ ë‹¤ìš´ë¡œë“œ", f"{filtered_traffic['recv'].sum()/1024/1024:.2f} MB")
            else:
                st.info("í˜„ì¬ í•„í„°ì™€ ì¼ì¹˜í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            st.info("ë„¤íŠ¸ì›Œí¬ ì „ì²´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¸ë˜í”½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
    # Advanced Analytics and Insights section removed - functionality not implemented
    
# Traffic trends analysis section removed
    
# Application insights section removed
    
    # Performance optimization
    if st.session_state.get('show_performance_optimization', False):
        st.markdown("---")
        st.subheader("âš¡ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ")
        
        # Performance optimization recommendations
        st.markdown("**ğŸ¯ ìµœì í™” ì œì•ˆ:**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“Š íŠ¸ë˜í”½ ìµœì í™”:**")
            st.write("â€¢ ëŒ€ì—­í­ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹ë³„")
            st.write("â€¢ QoS ì •ì±… ì„¤ì •ìœ¼ë¡œ ì¤‘ìš” íŠ¸ë˜í”½ ìš°ì„ ìˆœìœ„ ë¶€ì—¬")
            st.write("â€¢ ë¶ˆí•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì°¨ë‹¨ ê³ ë ¤")
            st.write("â€¢ íŠ¸ë˜í”½ ì…°ì´í•‘ìœ¼ë¡œ ëŒ€ì—­í­ ë¶„ë°° ìµœì í™”")
        
        with col2:
            st.markdown("**ğŸ”§ ë„¤íŠ¸ì›Œí¬ ìµœì í™”:**")
            st.write("â€¢ VLAN ë¶„í• ë¡œ ë„¤íŠ¸ì›Œí¬ ì„¸ê·¸ë©˜í…Œì´ì…˜")
            st.write("â€¢ ë¬´ì„  ì±„ë„ ìµœì í™”")
            st.write("â€¢ ë””ë°”ì´ìŠ¤ íŒì›¨ì–´ ì—…ë°ì´íŠ¸")
            st.write("â€¢ ë³´ì•ˆ ì •ì±… ê°•í™”")
        
        # Real-time performance metrics
        st.markdown("**ğŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ:**")
        
        # Calculate real performance metrics
        total_devices = len(filtered)
        online_devices = len([d for d in filtered if d.get('status') == 'online'])
        offline_devices = len([d for d in filtered if d.get('status') == 'offline'])
        alerting_devices = len([d for d in filtered if d.get('status') == 'alerting'])
        
        # Calculate network efficiency
        if total_devices > 0:
            network_efficiency = (online_devices / total_devices) * 100
        else:
            network_efficiency = 0
        
        # Calculate bandwidth utilization (if traffic data available)
        bandwidth_utilization = 0
        if enable_traffic:
            total_traffic_mb = 0
            for net_id in sel_nets:
                try:
                    traffic_data = load_traffic(api_key, net_id, timespan)
                    if traffic_data:
                        df = pd.DataFrame(traffic_data)
                        total_traffic_mb += (df["sent"].sum() + df["recv"].sum()) / (1024 * 1024)
                except:
                    continue
            # Assume 1Gbps = 125MB/s, calculate utilization
            if total_traffic_mb > 0:
                bandwidth_utilization = min((total_traffic_mb / (125 * 3600)) * 100, 100)  # 1 hour period
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ì„±", f"{network_efficiency:.1f}%", 
                     delta=f"{network_efficiency-85:.1f}%" if network_efficiency > 0 else None,
                     help="ì˜¨ë¼ì¸ ë””ë°”ì´ìŠ¤ ë¹„ìœ¨")
        with col2:
            st.metric("ëŒ€ì—­í­ í™œìš©ë¥ ", f"{bandwidth_utilization:.1f}%", 
                     delta=f"{bandwidth_utilization-72:.1f}%" if bandwidth_utilization > 0 else None,
                     help="ì‹¤ì œ íŠ¸ë˜í”½ ê¸°ë°˜ í™œìš©ë¥ ")
        with col3:
            device_health = ((total_devices - offline_devices - alerting_devices) / total_devices * 100) if total_devices > 0 else 0
            st.metric("ë””ë°”ì´ìŠ¤ ìƒíƒœ", f"{device_health:.1f}%", 
                     delta=f"{device_health-98:.1f}%" if device_health > 0 else None,
                     help="ì •ìƒ ì‘ë™ ë””ë°”ì´ìŠ¤ ë¹„ìœ¨")
        with col4:
            # Security score based on device status
            security_score = max(0, 100 - (offline_devices + alerting_devices) * 10)
            st.metric("ë³´ì•ˆ ì ìˆ˜", f"{security_score:.1f}%", 
                     delta=f"{security_score-92:.1f}%" if security_score > 0 else None,
                     help="ë””ë°”ì´ìŠ¤ ìƒíƒœ ê¸°ë°˜ ë³´ì•ˆ ì ìˆ˜")
            
            st.markdown("---")

elif current_page == "í´ë¼ì´ì–¸íŠ¸ ë¶„ì„":
    st.header("ğŸ‘¥ ê°œë³„ í´ë¼ì´ì–¸íŠ¸ ë¶„ì„ (íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ì˜ ìƒì„¸ íŠ¸ë˜í”½)")
    
    if not enable_clients:
        st.info("ğŸ”§ ì‚¬ì´ë“œë°”ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ë¶„ì„ì„ í™œì„±í™”í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    else:
        # Load client data only when user visits this page (on-demand loading)
        print("=" * 60)
        print("ON-DEMAND CLIENT ANALYSIS DATA LOADING")
        print("=" * 60)
        
        with st.spinner("í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘..."):
            client_data = load_client_analysis_data_parallel(api_key, sel_nets, timespan, resolution)
        
        print(f"âœ… Client analysis data loaded in {client_data['load_time']:.2f} seconds")
        print("=" * 60)
        
        # í´ë¼ì´ì–¸íŠ¸ ì„ íƒ ì„¹ì…˜
        st.markdown("### ğŸ“‹ í´ë¼ì´ì–¸íŠ¸ ì„ íƒ")
        
        # Extract data from parallel results
        all_clients = []
        network_clients_map = {}
        total_clients_overview = 0
        
        for net_id in sel_nets:
            display_name = next((name for name, nid in net_map.items() if nid == net_id), f"Network_{net_id}")
            
            # Get data from parallel results
            network_data = client_data['network_data'].get(net_id, {})
            clients_data = network_data.get('clients', [])
            clients_overview = network_data.get('clients_overview', {})
            
            # Get total client count from overview
            if clients_overview and 'counts' in clients_overview:
                total_clients_overview += clients_overview['counts'].get('total', 0)
            elif clients_overview and 'total' in clients_overview:
                total_clients_overview += clients_overview['total']
            
            if clients_data:
                network_clients_map[net_id] = {
                    'display_name': display_name,
                    'clients': clients_data
                }
                for client in clients_data:
                    client['network_id'] = net_id
                    client['network_name'] = display_name
                    all_clients.append(client)
        
        if not all_clients:
            st.warning("ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ì—ì„œ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # í´ë¼ì´ì–¸íŠ¸ ì„ íƒ UI
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # í´ë¼ì´ì–¸íŠ¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
                client_options = []
                for i, client in enumerate(all_clients):
                    client_name = client.get('description', client.get('hostname', f"Client_{i}"))
                    client_mac = client.get('mac', 'Unknown')
                    network_name = client.get('network_name', 'Unknown')
                    client_id = f"{client_name} ({client_mac}) - {network_name}"
                    client_options.append((client_id, i))
                
                selected_client_idx = st.selectbox(
                    "í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                    options=[idx for _, idx in client_options],
                    format_func=lambda x: client_options[x][0],
                    help="ë¶„ì„í•  í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                )
            
            
            # ì„ íƒëœ í´ë¼ì´ì–¸íŠ¸ ì •ë³´
            selected_client = all_clients[selected_client_idx]
            client_name = selected_client.get('description', selected_client.get('hostname', 'Unknown'))
            client_mac = selected_client.get('mac', 'Unknown')
            client_ip = selected_client.get('ip', 'Unknown')
            client_vlan = selected_client.get('vlan', 'Unknown')
            client_network = selected_client.get('network_name', 'Unknown')
            
            st.markdown("---")
            st.subheader(f"ğŸ‘¤ {client_name}")
            
            # í´ë¼ì´ì–¸íŠ¸ ê¸°ë³¸ ì •ë³´
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"**ğŸ–¥ï¸ í´ë¼ì´ì–¸íŠ¸ëª…:**<br><span class='client-name'>{client_name}</span>", unsafe_allow_html=True)
                st.markdown(f"**ğŸŒ ë„¤íŠ¸ì›Œí¬:**<br><span class='client-name'>{client_network}</span>", unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"**ğŸ“¡ MAC ì£¼ì†Œ:**<br><span class='mac-address'>{client_mac}</span>", unsafe_allow_html=True)
                st.markdown(f"**ğŸ”¢ IP ì£¼ì†Œ:**<br><span class='mac-address'>{client_ip}</span>", unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"**ğŸ·ï¸ VLAN:**<br><span class='client-name'>{client_vlan}</span>", unsafe_allow_html=True)
                status_text = "ì˜¨ë¼ì¸" if selected_client.get('status') == 'Online' else "ì˜¤í”„ë¼ì¸"
                st.markdown(f"**ğŸ“¶ ì—°ê²° ìƒíƒœ:**<br><span class='client-name'>{status_text}</span>", unsafe_allow_html=True)
            
            with col4:
                # í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©ëŸ‰ ì •ë³´
                usage = selected_client.get('usage', {})
                sent = usage.get('sent', 0)
                recv = usage.get('recv', 0)
                total_usage = sent + recv
                
                st.markdown(f"**ğŸ“¤ ì „ì†¡ëŸ‰:**<br><span class='client-name'>{sent / (1024*1024):.2f} MB</span>", unsafe_allow_html=True)
                st.markdown(f"**ğŸ“¥ ìˆ˜ì‹ ëŸ‰:**<br><span class='client-name'>{recv / (1024*1024):.2f} MB</span>", unsafe_allow_html=True)
            
            # í´ë¼ì´ì–¸íŠ¸ë³„ íŠ¸ë˜í”½ ë¶„ì„
            st.markdown("---")
            st.subheader("ğŸ“Š í´ë¼ì´ì–¸íŠ¸ íŠ¸ë˜í”½ ë¶„ì„")
            
            # í´ë¼ì´ì–¸íŠ¸ë³„ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½ ë¶„ì„
            client_network_id = selected_client.get('network_id')
            
            # í•´ë‹¹ ë„¤íŠ¸ì›Œí¬ì˜ ëª¨ë“  ë””ë°”ì´ìŠ¤ íƒ€ì… íŠ¸ë˜í”½ ë°ì´í„° ë¡œë“œ
            comprehensive_traffic = load_comprehensive_traffic(api_key, client_network_id, timespan)
            
            if comprehensive_traffic:
                # í´ë¼ì´ì–¸íŠ¸ë³„ íŠ¸ë˜í”½ í•„í„°ë§
                client_traffic = []
                for device_type, traffic_data in comprehensive_traffic.items():
                    if traffic_data:
                        for app in traffic_data:
                            # í´ë¼ì´ì–¸íŠ¸ MACì´ë‚˜ IPë¡œ í•„í„°ë§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë§¤ì¹­ í•„ìš”)
                            if (client_mac in str(app.get('destination', '')) or 
                                client_ip in str(app.get('destination', '')) or
                                client_mac in str(app.get('source', '')) or
                                client_ip in str(app.get('source', ''))):
                                app_copy = app.copy()
                                app_copy['deviceType'] = device_type
                                client_traffic.append(app_copy)
                
            if client_traffic:
                # í´ë¼ì´ì–¸íŠ¸ íŠ¸ë˜í”½ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                client_df = pd.DataFrame(client_traffic)
                client_df["sent_MB"] = client_df["sent"] / (1024 * 1024)
                client_df["recv_MB"] = client_df["recv"] / (1024 * 1024)
                client_df["TotalMB"] = client_df["sent_MB"] + client_df["recv_MB"]
                
                # í´ë¼ì´ì–¸íŠ¸ íŠ¸ë˜í”½ ë©”íŠ¸ë¦­
                total_sent_mb = client_df["sent_MB"].sum()
                total_recv_mb = client_df["recv_MB"].sum()
                total_traffic_mb = total_sent_mb + total_recv_mb
                total_clients = client_df["numClients"].sum()
                        
                col1, col2, col3, col4 = st.columns(4)
                        
                with col1:
                    st.metric("ğŸ“Š ì´ íŠ¸ë˜í”½", f"{total_traffic_mb:.2f} MB")
                    st.metric("ğŸ“¤ ì—…ë¡œë“œ", f"{total_sent_mb:.2f} MB")
                        
                with col2:
                    st.metric("ğŸ“¥ ë‹¤ìš´ë¡œë“œ", f"{total_recv_mb:.2f} MB")
                    st.metric("ğŸ‘¥ ê´€ë ¨ í´ë¼ì´ì–¸íŠ¸", f"{total_clients}")
                        
                with col3:
                    # ìƒìœ„ ì• í”Œë¦¬ì¼€ì´ì…˜
                    top_apps = client_df.nlargest(5, "TotalMB")
                    st.metric("ğŸ”¥ ìƒìœ„ ì•±", top_apps.iloc[0]["application"] if len(top_apps) > 0 else "N/A")
                    st.metric("ğŸ“± ì•± ìˆ˜", f"{len(client_df)}ê°œ")
                        
                with col4:
                    # ë””ë°”ì´ìŠ¤ íƒ€ì… ë¶„í¬
                    device_types = client_df["deviceType"].value_counts()
                    st.metric("ğŸ”Œ ì£¼ìš” ë””ë°”ì´ìŠ¤", device_types.index[0] if len(device_types) > 0 else "N/A")
                    st.metric("ğŸ“Š ë””ë°”ì´ìŠ¤ íƒ€ì…", f"{len(device_types)}ê°œ")
                
                # í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½ ì°¨íŠ¸
                st.markdown("---")
                st.subheader("ğŸ“ˆ í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½")
                
                if len(client_df) > 0:
                    # ìƒìœ„ 10ê°œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì°¨íŠ¸
                    top_10_apps = client_df.nlargest(10, "TotalMB")
                    
                    # Use plotly graph objects directly to avoid narwhals compatibility issues
                    fig = go.Figure(data=[
                        go.Bar(
                            x=top_10_apps["TotalMB"],
                            y=top_10_apps["application"],
                            orientation='h',
                            text=top_10_apps["TotalMB"].round(1),
                            texttemplate='%{text:.1f}MB',
                            textposition='outside',
                            marker=dict(
                                color=top_10_apps["TotalMB"],
                                colorscale='Viridis',
                                showscale=True
                            )
                        )
                    ])
                    fig.update_layout(
                        title=f"{client_name} - ìƒìœ„ ì• í”Œë¦¬ì¼€ì´ì…˜ íŠ¸ë˜í”½",
                        xaxis_title="Total MB",
                        yaxis_title="Application",
                        height=400
                    )
                    
                    fig.update_layout(
                        height=max(400, len(top_10_apps) * 30),
                        xaxis_title="íŠ¸ë˜í”½ (MB)",
                        yaxis_title="ì• í”Œë¦¬ì¼€ì´ì…˜",
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                # í´ë¼ì´ì–¸íŠ¸ ìƒì„¸ í…Œì´ë¸”
                st.markdown("---")
                st.subheader("ğŸ“‹ í´ë¼ì´ì–¸íŠ¸ ìƒì„¸ íŠ¸ë˜í”½ í…Œì´ë¸”")
                
                display_df = client_df[['application', 'TotalMB', 'sent_MB', 'recv_MB', 'numClients', 'deviceType', 'protocol', 'port']].copy()
                display_df = display_df.sort_values('TotalMB', ascending=False)
                display_df['TotalMB'] = display_df['TotalMB'].round(2)
                display_df['sent_MB'] = display_df['sent_MB'].round(2)
                display_df['recv_MB'] = display_df['recv_MB'].round(2)
                        
                st.dataframe(
                    display_df.rename(columns={
                        'application': 'ì• í”Œë¦¬ì¼€ì´ì…˜',
                        'TotalMB': 'ì´ íŠ¸ë˜í”½ (MB)',
                        'sent_MB': 'ì—…ë¡œë“œ (MB)',
                        'recv_MB': 'ë‹¤ìš´ë¡œë“œ (MB)',
                        'numClients': 'í´ë¼ì´ì–¸íŠ¸ ìˆ˜',
                        'deviceType': 'ë””ë°”ì´ìŠ¤ íƒ€ì…',
                        'protocol': 'í”„ë¡œí† ì½œ',
                        'port': 'í¬íŠ¸'
                    }),
                    use_container_width=True,
                    hide_index=True
                )
        
 

elif current_page == "ìŠ¤ìœ„ì¹˜ í¬íŠ¸":
    st.header("ğŸ”Œ ìŠ¤ìœ„ì¹˜ í¬íŠ¸ ë¶„ì„ (í¬íŠ¸ ìƒíƒœ,ì„¤ì •ê°’) ")
    
    if not enable_switch_ports:
        st.info("ğŸ”§ Enable Switch Port Analysis in the sidebar to view port data")
    else:
        sw_data = load_switch_ports(api_key, org_id)
        
        if not sw_data:
            st.warning("âš ï¸ No switch data available")
        else:
            # Switch selection with better labels
            switch_options = []
            for switch_id, switch_ports in sw_data.items():
                # Try to get a meaningful name from the first port's device info
                if switch_ports and len(switch_ports) > 0:
                    first_port = switch_ports[0]
                    device_name = first_port.get("deviceName", "")
                    description = first_port.get("description", "")
                    
                    if device_name and device_name != "N/A":
                        label = f"{device_name} ({switch_id})"
                    elif description and description != "N/A":
                        label = f"{description} ({switch_id})"
                    else:
                        label = f"Switch {switch_id}"
                else:
                    label = f"Switch {switch_id}"
                
                switch_options.append((label, switch_id))
            
            # Create a mapping for display
            switch_display_map = {label: switch_id for label, switch_id in switch_options}
            
            if len(switch_options) > 1:
                sel_sw_label = st.selectbox("Select Switch", list(switch_display_map.keys()), key="switch_selection")
                sel_sw = switch_display_map[sel_sw_label]
            else:
                # If only one switch, show it directly
                sel_sw_label = switch_options[0][0]
                sel_sw = switch_options[0][1]
            
            ports = sw_data[sel_sw]
            
            if not ports:
                st.info(f"ìŠ¤ìœ„ì¹˜ì˜ í¬íŠ¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {sel_sw}")
            else:
                # Port metrics
                total_ports = len(ports)
                connected_ports = sum(1 for p in ports if p.get("status", "").lower() == "connected")
                disconnected_ports = sum(1 for p in ports if p.get("status", "").lower() == "disconnected")
                error_ports = sum(1 for p in ports if p.get("status", "").lower() in ["error", "alerting"])
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ğŸ”Œ ì´ í¬íŠ¸", total_ports)
                with col2:
                    st.metric("âœ… ì—°ê²°ë¨", f"{connected_ports}/{total_ports}")
                with col3:
                    st.metric("âŒ ì—°ê²° ëŠê¹€", f"{disconnected_ports}/{total_ports}")
                with col4:
                    st.metric("âš ï¸ ì˜¤ë¥˜", f"{error_ports}/{total_ports}")
                
                st.markdown("---")
                
                # Port status visualization - HIDDEN (ìˆ¨ê¹€ ì²˜ë¦¬)
                # col1, col2 = st.columns(2)
                  

               
                
                # Comprehensive Switch Port Analysis Table
                st.subheader("ğŸ“Š í¬íŠ¸ ìƒì„¸ ì„¤ì •ì •ë³´")
                
                if ports:
                    # Create comprehensive port analysis data with colored status
                    port_analysis = []
                    for port in ports:
                        status = port.get("status", "N/A")
                        
                        # Add color coding to status based on port status
                        if status.lower() in ["connected", "up", "active"]:
                            colored_status = f'<span style="color: #059669; font-weight: 600;">ğŸŸ¢ {status}</span>'
                        elif status.lower() in ["disconnected", "down", "error", "failed"]:
                            colored_status = f'<span style="color: #dc2626; font-weight: 600;">ğŸ”´ {status}</span>'
                        elif status.lower() in ["warning", "degraded", "partial"]:
                            colored_status = f'<span style="color: #d97706; font-weight: 600;">ğŸŸ¡ {status}</span>'
                        elif status.lower() in ["disabled", "dormant", "inactive"]:
                            colored_status = f'<span style="color: #6b7280; font-weight: 600;">âš« {status}</span>'
                        else:
                            colored_status = f'<span style="color: #6b7280; font-weight: 600;">âšª {status}</span>'
                        
                        # Convert VLAN to int if it's a number, otherwise keep as is
                        vlan_value = port.get("vlan", "N/A")
                        if isinstance(vlan_value, (int, float)) and not pd.isna(vlan_value):
                            vlan_value = int(vlan_value)
                        elif vlan_value is None or pd.isna(vlan_value):
                            vlan_value = "N/A"
                        
                        port_analysis.append({
                            "Port ID": port.get("portId", "N/A"),
                            "Status": colored_status,
                            "Speed": port.get("speed", "Null") if port.get("speed") else "Null",
                            "Duplex": port.get("duplex", "N/A"),
                            "Enabled": port.get("enabled", "N/A"),
                            "Description": port.get("description", "N/A"),
                            "Type": port.get("type", "N/A"),
                            "VLAN": vlan_value,
                            "STP Guard": port.get("stpGuard", "N/A"),
                            "Device Name": port.get("deviceName", "N/A")
                        })
                    
                    port_analysis_df = pd.DataFrame(port_analysis)
                    
                    # Add filtering options for the comprehensive table
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        min_ports = st.number_input("Minimum Ports per Status", min_value=1, value=1, step=1, key="port_min_filter")
                    with col2:
                        status_search = st.text_input("Search by Status", placeholder="e.g., Connected, Error", key="port_status_search")
                    with col3:
                        speed_search = st.text_input("Search by Speed", placeholder="e.g., 1000, 100", key="port_speed_search")
                    
                    # Apply filters to comprehensive table
                    filtered_analysis = port_analysis_df.copy()
                    
                    if status_search:
                        filtered_analysis = filtered_analysis[filtered_analysis["Status"].str.contains(status_search, case=False, na=False)]
                    
                    if speed_search:
                        filtered_analysis = filtered_analysis[filtered_analysis["Speed"].str.contains(speed_search, case=False, na=False)]
                    
                    # Display filtered comprehensive table with HTML rendering
                    if len(filtered_analysis) > 0:
                        # Add CSS for clean table styling
                        st.markdown("""
                        <style>
                        .styled-table {
                            border-collapse: collapse;
                            margin: 15px 0;
                            font-size: 0.9em;
                            font-family: sans-serif;
                            width: 100%;
                            border: 1px solid #e5e7eb;
                        }
                        .styled-table thead tr {
                            background-color: #f8fafc;
                            color: #374151;
                            text-align: center;
                            font-weight: 600;
                        }
                        .styled-table th,
                        .styled-table td {
                            padding: 8px 12px;
                            border: 1px solid #e5e7eb;
                            text-align: center;
                        }
                        .styled-table tbody tr {
                            border-bottom: 1px solid #e5e7eb;
                        }
                        .styled-table tbody tr:nth-of-type(even) {
                            background-color: #fafafa;
                        }
                        .styled-table tbody tr:hover {
                            background-color: #f0f9ff;
                        }
                        </style>
                        """, unsafe_allow_html=True)
                        
                        # Convert DataFrame to HTML to render colored status
                        html_table = filtered_analysis.to_html(escape=False, index=False, classes="styled-table")
                        st.markdown(html_table, unsafe_allow_html=True)
                        
                        # Summary metrics for comprehensive analysis - HIDDEN (ìˆ¨ê¹€ ì²˜ë¦¬)
                        # col1, col2, col3, col4 = st.columns(4)
                        # with col1:
                        #     st.metric("Total Ports", len(filtered_analysis))
                        # with col2:
                        #     connected_count = len(filtered_analysis[filtered_analysis["Status"] == "Connected"])
                        #     st.metric("Connected", connected_count)
                        # with col3:
                        #     error_count = len(filtered_analysis[filtered_analysis["Status"] == "Error"])
                        #     st.metric("Errors", error_count)
                        # with col4:
                        #     unique_speeds = filtered_analysis["Speed"].nunique()
                        #     st.metric("Speed Types", unique_speeds)
                        
                        # Port status summary by speed - HIDDEN (ìˆ¨ê¹€ ì²˜ë¦¬)
                        # st.markdown("**ğŸ“ˆ Port Status by Speed:**")
                        # speed_status_summary = filtered_analysis.groupby(["Speed", "Status"]).size().unstack(fill_value=0)
                        # st.dataframe(speed_status_summary, use_container_width=True)
                        
                    else:
                        st.info("No ports match the comprehensive analysis filters")
                else:
                    st.info("No port data available for comprehensive analysis")
                


elif current_page == "ë””ë°”ì´ìŠ¤ ìƒíƒœ ì•Œë¦¼":
    st.header("ğŸš¨ ë””ë°”ì´ìŠ¤ ìƒíƒœ ì•Œë¦¼ (ë””ë°”ì´ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ì˜¤ë¥˜ ê°ì§€)")
    
    if not enable_alerts:
        st.info("ğŸ”§ ì•Œë¦¼ ë° ì˜¤ë¥˜ ë¶„ì„ì„ ìœ„í•´ ì‚¬ì´ë“œë°”ì—ì„œ í™œì„±í™”í•´ì£¼ì„¸ìš”")
    else:
        # Load device alerts data only when user visits this page (on-demand loading)
        print("=" * 60)
        print("ON-DEMAND DEVICE ALERTS DATA LOADING")
        print("=" * 60)
        
        # Get device serials for parallel loading
        device_serials = [d.get('serial') for d in filtered if d.get('serial')]
        
        if device_serials:
            with st.spinner("ë””ë°”ì´ìŠ¤ ì•Œë¦¼ ë°ì´í„° ë¡œë”© ì¤‘..."):
                alerts_data = load_device_alerts_data_parallel(api_key, org_id, device_serials)
            print(f"âœ… Device alerts data loaded in {alerts_data['load_time']:.2f} seconds")
        else:
            alerts_data = {'device_data': {}, 'load_time': 0}
            print("âš ï¸ No device serials found for alerts loading")
        
        print("=" * 60)
        
        # Filter devices by status
        offline_devices = [d for d in filtered if d["status"] == "offline"]
        alerting_devices = [d for d in filtered if d["status"] == "alerting"]
        online_devices = [d for d in filtered if d["status"] == "online"]
        dormant_devices = [d for d in filtered if d["status"] == "dormant"]
        
        # Simple status summary
        total_devices = len(filtered)
        total_issues = len(offline_devices) + len(alerting_devices)
        
        if total_issues > 0:
            # Show critical issues
            st.error(f"ğŸš¨ **{total_issues} ë””ë°”ì´ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤**")
            
            # Device status breakdown
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âœ… Online", len(online_devices), delta_color="normal")
            with col2:
                st.metric("âŒ Offline", len(offline_devices), delta_color="inverse")
            with col3:
                st.metric("âš ï¸ Alerting", len(alerting_devices), delta_color="inverse")
            with col4:
                st.metric("ğŸ˜´ Dormant", len(dormant_devices), delta_color="normal")
            
            st.markdown("---")
            
            # Show problematic devices
            if offline_devices:
                st.error("âŒ **ì˜¤í”„ë¼ì¸ ë””ë°”ì´ìŠ¤**")
                for device in offline_devices:
                    network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                    st.write(f"â€¢ **{device.get('name', 'Unknown')}** ({network_name})")
                    st.write(f"  - Model: {device.get('model', 'N/A')}")
                    st.write(f"  - Serial: {device.get('serial', 'N/A')}")
                    st.write("---")
            
            if alerting_devices:
                st.warning("âš ï¸ **ì•Œë¦¼ ë””ë°”ì´ìŠ¤**")
                for device in alerting_devices:
                    network_name = next((name for name, net_id in net_map.items() if net_id == device["networkId"]), "Unknown")
                    st.write(f"â€¢ **{device.get('name', 'Unknown')}** ({network_name})")
                    st.write(f"  - Model: {device.get('model', 'N/A')}")
                    st.write(f"  - Serial: {device.get('serial', 'N/A')}")
                    st.write("---")
        else:
            # All systems operational
            st.success("âœ… **ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™**")
            st.info("ë””ë°”ì´ìŠ¤ ìƒíƒœ ë¬¸ì œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # Simple health summary
            if total_devices > 0:
                # Only decrease health for confirmed errors (offline, alerting)
                # Dormant devices don't affect health score
                confirmed_errors = len(offline_devices) + len(alerting_devices)
                if confirmed_errors == 0:
                    health_percentage = 100.0
                else:
                    health_percentage = ((total_devices - confirmed_errors) / total_devices) * 100
                
                st.metric("Network Health", f"{health_percentage:.1f}%", 
                         delta_color="normal" if health_percentage == 100 else "inverse")
    
    # Configuration Changes Section
    st.markdown("---")
    st.subheader("ğŸ“‹ ì„¤ì • ë³€ê²½ ë‚´ì—­ (ì¡°ì§ ì„¤ì • ë³€ê²½ ê¸°ë¡)")
    
    # Fixed per_page value
    per_page = 3000
    
    # Generate text report button
    if st.button("ğŸ“„ Generate Text Report", key="generate_config_report", use_container_width=True):
        with st.spinner("Loading configuration changes..."):
            config_changes = load_configuration_changes(api_key, org_id, per_page)
            
            if config_changes:
                st.success(f"âœ… Loaded {len(config_changes)} configuration changes")
                
                # Convert all data to text format without preprocessing
                text_content = "=== MERAKI CONFIGURATION CHANGES REPORT ===\n"
                text_content += f"Organization ID: {org_id}\n"
                text_content += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                text_content += f"Total Records: {len(config_changes)}\n"
                text_content += "=" * 50 + "\n\n"
                
                # Add each configuration change as raw text
                for i, change in enumerate(config_changes, 1):
                    text_content += f"--- Configuration Change #{i} ---\n"
                    text_content += f"Raw Data: {str(change)}\n"
                    text_content += "\n"
                
                # Store in session state for download
                st.session_state['config_changes_text'] = text_content
                st.session_state['config_changes_filename'] = f"meraki_config_changes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                st.rerun()
            else:
                st.warning("No configuration changes found or failed to load data")
    
    # Show download button if text content is ready
    if 'config_changes_text' in st.session_state:
        st.markdown("#### ğŸ“¥ ì„¤ì • ë³€ê²½ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°")
        st.download_button(
            label="ğŸ“¥ Download Configuration Changes as Text File",
            data=st.session_state['config_changes_text'],
            file_name=st.session_state['config_changes_filename'],
            mime="text/plain",
            key="download_config_changes",
            width='stretch'
        )
        
        # Clear the session state after showing download button
        if st.button("ğŸ—‘ï¸ ë³´ê³ ì„œ ì´ˆê¸°í™”", key="clear_config_report"):
            del st.session_state['config_changes_text']
            del st.session_state['config_changes_filename']
            st.rerun()

elif current_page == "ë¼ì´ì„¼ìŠ¤ ì •ë³´":
    st.header("ğŸ“„ ë¼ì´ì„¼ìŠ¤ ì •ë³´ (ì¡°ì§ ë¼ì´ì„¼ìŠ¤ í˜„í™© ë° ìƒì„¸ ì •ë³´)")
    
    # Load license data only when user visits this page (on-demand loading)
    print("=" * 60)
    print("ON-DEMAND LICENSE DATA LOADING")
    print("=" * 60)
    
    with st.spinner("ë¼ì´ì„¼ìŠ¤ ë°ì´í„° ë¡œë”© ì¤‘..."):
        license_overview = load_license_overview(api_key, org_id)
    
    print(f"âœ… License data loaded on-demand")
    print("=" * 60)
    
    # Add CSS to prevent text truncation in metrics and increase font size
    st.markdown("""
    <style>
    /* Prevent text truncation in metrics and increase font size */
    div[data-testid="stMetricValue"] {
        white-space: nowrap !important;
        overflow: visible !important;
        text-overflow: unset !important;
        font-size: 2rem !important;
        font-weight: 600 !important;
    }
    div[data-testid="stMetricLabel"] {
        white-space: nowrap !important;
        overflow: visible !important;
        text-overflow: unset !important;
        font-size: 1.1rem !important;
        font-weight: 500 !important;
    }
    /* Increase column width for metrics */
    div[data-testid="column"] {
        min-width: 200px !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # License Overview Section
    st.subheader("ğŸ“Š ë¼ì´ì„¼ìŠ¤ ê°œìš”")
    
    
    if license_overview:
            
            # Display overview metrics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if 'status' in license_overview:
                    status = license_overview['status']
                    st.metric("ğŸ“‹ ë¼ì´ì„¼ìŠ¤ ìƒíƒœ", status)
            
            with col2:
                if 'expirationDate' in license_overview:
                    exp_date = license_overview['expirationDate']
                    # Format date for better display
                    if exp_date and exp_date != 'N/A':
                        try:
                            # Parse and format date
                            from datetime import datetime
                            parsed_date = datetime.fromisoformat(exp_date.replace('Z', '+00:00'))
                            formatted_date = parsed_date.strftime('%Y-%m-%d')
                        except:
                            formatted_date = exp_date
                    else:
                        formatted_date = exp_date
                    st.metric("ğŸ“… ë§Œë£Œì¼", formatted_date)
            
            with col3:
                if 'licensedDeviceCounts' in license_overview:
                    device_counts = license_overview['licensedDeviceCounts']
                    total_devices = sum(device_counts.values()) if device_counts else 0
                    st.metric("ğŸ”¢ ì´ ë¼ì´ì„¼ìŠ¤ ë””ë°”ì´ìŠ¤", total_devices)
            
            with col4:
                if 'usedDeviceCounts' in license_overview:
                    used_counts = license_overview['usedDeviceCounts']
                    total_used = sum(used_counts.values()) if used_counts else 0
                    st.metric("ğŸ“± ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤", total_used)
            
            # Display license comparison table
            st.markdown("---")
            st.markdown("#### ğŸ“‹ ë¼ì´ì„¼ìŠ¤ ê°œìˆ˜")
            
            # Debug: Show what's in license_overview
            if SHOW_DEBUG_INFO:
                st.write("Debug - license_overview keys:", list(license_overview.keys()))
                st.write("Debug - license_overview values:", license_overview)
            
            # Create license comparison table
            license_data = []
            
            # Get licensed and used device counts
            licensed_counts = license_overview.get('licensedDeviceCounts', {})
            used_counts = license_overview.get('usedDeviceCounts', {})
            
            # Get all product types from both dictionaries
            all_products = set(licensed_counts.keys()) | set(used_counts.keys())
            
            for product in sorted(all_products):
                license_limit = licensed_counts.get(product, 0)
                current_count = used_counts.get(product, 0)
                
                # Format license limit (show "free" for 0, or specific number)
                if license_limit == 0:
                    limit_display = "ë¬´ì œí•œ"
                else:
                    limit_display = str(license_limit)
                
                # Format current count
                if current_count == 0:
                    count_display = "0"
                else:
                    count_display = str(current_count)
                
                license_data.append({
                    "ì œí’ˆ íƒ€ì…": product,
                    "ë¼ì´ì„¼ìŠ¤ ê°œìˆ˜": limit_display
                })
            
            if license_data:
                license_df = pd.DataFrame(license_data)
                # Make table smaller and center-aligned
                st.dataframe(
                    license_df, 
                    use_container_width=False,
                    hide_index=True,
                    column_config={
                        "ì œí’ˆ íƒ€ì…": st.column_config.TextColumn("ì œí’ˆ íƒ€ì…", width="medium"),
                        "ë¼ì´ì„¼ìŠ¤ í•œë„": st.column_config.TextColumn("ë¼ì´ì„¼ìŠ¤ í•œë„", width="small")
                    }
                )
            else:
                st.info("ë¼ì´ì„¼ìŠ¤ ê°œìš”ì—ì„œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                if SHOW_DEBUG_INFO:
                    st.write("Debug - license_data is empty")
                    st.write("Debug - licensed_counts:", licensed_counts)
                    st.write("Debug - used_counts:", used_counts)
    else:
        st.warning("âš ï¸ ë¼ì´ì„¼ìŠ¤ ê°œìš” ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        st.info("ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
        st.write("â€¢ API í‚¤ì— ë¼ì´ì„¼ìŠ¤ ì •ë³´ ì ‘ê·¼ ê¶Œí•œì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        st.write("â€¢ ì¡°ì§ì— ë¼ì´ì„¼ìŠ¤ ì •ë³´ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        st.write("â€¢ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # Try to load with different methods
        st.write("ğŸ”„ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë¼ì´ì„¼ìŠ¤ ì •ë³´ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
        try:
            # Try to get basic organization info
            api = init_api(api_key)
            if api:
                org_info = api.organizations.getOrganization(organizationId=org_id)
                st.write(f"ì¡°ì§ ì •ë³´: {org_info.get('name', 'Unknown')}")
        except Exception as e:
            st.write(f"ì¡°ì§ ì •ë³´ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    # Detailed Licenses Section - Auto load with per_page=1000
    st.markdown("---")
    st.subheader("ğŸ“‹ ìƒì„¸ ë¼ì´ì„¼ìŠ¤ ëª©ë¡")
    
    with st.spinner("ìƒì„¸ ë¼ì´ì„¼ìŠ¤ ì •ë³´ë¥¼ ë¡œë”© ì¤‘..."):
        detailed_licenses = load_detailed_licenses(api_key, org_id, per_page=1000)
        
        # Debug information
        if SHOW_DEBUG_INFO:
            st.write(f"Debug: detailed_licenses type: {type(detailed_licenses)}")
            st.write(f"Debug: detailed_licenses length: {len(detailed_licenses) if detailed_licenses else 'None'}")
            if detailed_licenses:
                st.write(f"Debug: First license sample: {detailed_licenses[0] if len(detailed_licenses) > 0 else 'Empty'}")
        
        if detailed_licenses:
            st.success(f"âœ… {len(detailed_licenses)}ê°œì˜ ìƒì„¸ ë¼ì´ì„¼ìŠ¤ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
            
            # Create detailed licenses table
            licenses_data = []
            for license_info in detailed_licenses:
                # Extract editions information
                editions = license_info.get('editions', [])
                edition_info = ""
                if editions:
                    edition_list = []
                    for edition in editions:
                        edition_name = edition.get('edition', 'N/A')
                        product_type = edition.get('productType', 'N/A')
                        edition_list.append(f"{edition_name} ({product_type})")
                    edition_info = ", ".join(edition_list)
                else:
                    edition_info = "N/A"
                
                # Extract counts information
                counts = license_info.get('counts', [])
                count_info = ""
                if counts:
                    count_list = []
                    for count in counts:
                        model = count.get('model', 'N/A')
                        count_num = count.get('count', 0)
                        count_list.append(f"{model}: {count_num}")
                    count_info = ", ".join(count_list)
                else:
                    count_info = "N/A"
                
                licenses_data.append({
                    "ë¼ì´ì„¼ìŠ¤ í‚¤": license_info.get('key', 'N/A'),
                    "ê¸°ê°„ (ì¼)": license_info.get('duration', 'N/A'),
                    "ëª¨ë“œ": license_info.get('mode', 'N/A'),
                    "ì‹œì‘ì¼": parse_date(license_info.get('startedAt', 'N/A')),
                    "í´ë ˆì„ì¼": parse_date(license_info.get('claimedAt', 'N/A')),
                    "ì—ë””ì…˜": edition_info,
                    "ëª¨ë¸ë³„ ìˆ˜ëŸ‰": count_info
                })
            
            licenses_df = pd.DataFrame(licenses_data)
            
            # Display the table
            st.dataframe(licenses_df, use_container_width=True, hide_index=True)

